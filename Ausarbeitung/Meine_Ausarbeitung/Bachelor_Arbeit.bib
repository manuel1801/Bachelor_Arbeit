
@article{sermanetOverFeatIntegratedRecognition,
  langid = {english},
  title = {{{OverFeat}}: {{Integrated Recognition}}, {{Localization}} and {{Detection}} Using {{Convolutional Networks}}},
  abstract = {We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.},
  pages = {16},
  author = {Sermanet, Pierre and Eigen, David and Zhang, Xiang and Mathieu, Michael and Fergus, Rob and LeCun, Yann},
  file = {/home/manuel/Zotero/storage/I679DNS9/Sermanet et al. - OverFeat Integrated Recognition, Localization and.pdf}
}

@inproceedings{hornINaturalistSpeciesClassification2018,
  langid = {english},
  location = {{Salt Lake City, UT}},
  title = {The {{iNaturalist Species Classification}} and {{Detection Dataset}}},
  isbn = {978-1-5386-6420-9},
  url = {https://ieeexplore.ieee.org/document/8579012/},
  doi = {10.1109/CVPR.2018.00914},
  abstract = {Existing image classification datasets used in computer vision tend to have a uniform distribution of images across object categories. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the iNaturalist species classification and detection dataset, consisting of 859,000 images from over 5,000 different species of plants and animals. It features visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, feature a large class imbalance, and have been verified by multiple citizen scientists. We discuss the collection of the dataset and present extensive baseline experiments using state-of-the-art computer vision classification and detection models. Results show that current nonensemble based methods achieve only 67\% top one classification accuracy, illustrating the difficulty of the dataset. Specifically, we observe poor results for classes with small numbers of training examples suggesting more attention is needed in low-shot learning.},
  eventtitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  booktitle = {2018 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  publisher = {{IEEE}},
  urldate = {2019-12-04},
  date = {2018-06},
  pages = {8769-8778},
  author = {Horn, Grant Van and Aodha, Oisin Mac and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  file = {/home/manuel/Zotero/storage/VVANFVGC/Horn et al. - 2018 - The iNaturalist Species Classification and Detecti.pdf}
}

@article{zhaoObjectDetectionDeep2019,
  langid = {english},
  title = {Object {{Detection With Deep Learning}}: {{A Review}}},
  volume = {30},
  issn = {2162-237X, 2162-2388},
  url = {https://ieeexplore.ieee.org/document/8627998/},
  doi = {10.1109/TNNLS.2018.2876865},
  shorttitle = {Object {{Detection With Deep Learning}}},
  abstract = {Due to object detection’s close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.},
  number = {11},
  journaltitle = {IEEE Transactions on Neural Networks and Learning Systems},
  shortjournal = {IEEE Trans. Neural Netw. Learning Syst.},
  urldate = {2019-12-04},
  date = {2019-11},
  pages = {3212-3232},
  author = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-Tao and Wu, Xindong},
  file = {/home/manuel/Zotero/storage/PQ8IY8CU/Zhao et al. - 2019 - Object Detection With Deep Learning A Review.pdf}
}

@article{shenSurveyObjectClassification,
  langid = {english},
  title = {A Survey of {{Object Classiﬁcation}} and {{Detection}} Based on {{2D}}/{{3D}} Data},
  abstract = {Recently, by using deep neural network based algorithms, object classification, detection and semantic segmentation solutions are significantly improved. However, one challenge for 2D image-based systems is that they cannot provide accurate 3D location information. This is critical for location sensitive applications such as autonomous driving and robot navigation. On the other hand, 3D methods, such as RGB-D and RGB-LiDAR based systems, can provide solutions that significantly improve the RGB only approaches. That is why this is an interesting research area for both industry and academia.},
  pages = {83},
  author = {Shen, Xiaoke},
  file = {/home/manuel/Zotero/storage/LAZVBNUU/Shen - A survey of Object Classiﬁcation and Detection bas.pdf}
}

@inproceedings{nguyenAnimalRecognitionIdentification2017,
  langid = {english},
  location = {{Tokyo, Japan}},
  title = {Animal {{Recognition}} and {{Identification}} with {{Deep Convolutional Neural Networks}} for {{Automated Wildlife Monitoring}}},
  isbn = {978-1-5090-5004-8},
  url = {http://ieeexplore.ieee.org/document/8259762/},
  doi = {10.1109/DSAA.2017.31},
  abstract = {Efficient and reliable monitoring of wild animals in their natural habitats is essential to inform conservation and management decisions. Automatic covert cameras or “camera traps” are being an increasingly popular tool for wildlife monitoring due to their effectiveness and reliability in collecting data of wildlife unobtrusively, continuously and in large volume. However, processing such a large volume of images and videos captured from camera traps manually is extremely expensive, time-consuming and also monotonous. This presents a major obstacle to scientists and ecologists to monitor wildlife in an open environment. Leveraging on recent advances in deep learning techniques in computer vision, we propose in this paper a framework to build automated animal recognition in the wild, aiming at an automated wildlife monitoring system. In particular, we use a single-labeled dataset from Wildlife Spotter project, done by citizen scientists, and the state-of-the-art deep convolutional neural network architectures, to train a computational system capable of filtering animal images and identifying species automatically. Our experimental results achieved an accuracy at 96.6\% for the task of detecting images containing animal, and 90.4\% for identifying the three most common species among the set of images of wild animals taken in South-central Victoria, Australia, demonstrating the feasibility of building fully automated wildlife observation. This, in turn, can therefore speed up research findings, construct more efficient citizen sciencebased monitoring systems and subsequent management decisions, having the potential to make significant impacts to the world of ecology and trap camera images analysis.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  booktitle = {2017 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  publisher = {{IEEE}},
  urldate = {2019-12-04},
  date = {2017-10},
  pages = {40-49},
  author = {Nguyen, Hung and Maclagan, Sarah J. and Nguyen, Tu Dinh and Nguyen, Thin and Flemons, Paul and Andrews, Kylie and Ritchie, Euan G. and Phung, Dinh},
  file = {/home/manuel/Zotero/storage/F3F74K6K/Nguyen et al. - 2017 - Animal Recognition and Identification with Deep Co.pdf}
}

@article{redmonYOLOv3IncrementalImprovement,
  langid = {english},
  title = {{{YOLOv3}}: {{An Incremental Improvement}}},
  abstract = {We present some updates to YOLO! We made a bunch of little design changes to make it better. We also trained this new network that’s pretty swell. It’s a little bigger than last time but more accurate. It’s still fast though, don’t worry. At 320 × 320 YOLOv3 runs in 22 ms at 28.2 mAP, as accurate as SSD but three times faster. When we look at the old .5 IOU mAP detection metric YOLOv3 is quite good. It achieves 57.9 AP50 in 51 ms on a Titan X, compared to 57.5 AP50 in 198 ms by RetinaNet, similar performance but 3.8× faster. As always, all the code is online at https://pjreddie.com/yolo/.},
  pages = {6},
  author = {Redmon, Joseph and Farhadi, Ali},
  file = {/home/manuel/Zotero/storage/GCC2R7AA/Redmon and Farhadi - YOLOv3 An Incremental Improvement.pdf}
}

@online{ouaknineReviewDeepLearning2018,
  langid = {english},
  title = {Review of {{Deep Learning Algorithms}} for {{Object Detection}}},
  url = {https://medium.com/zylapp/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852},
  abstract = {Why object detection instead of image classification?},
  journaltitle = {Medium},
  urldate = {2019-12-04},
  date = {2018-02-05T13:47:12.719Z},
  author = {Ouaknine, Arthur},
  file = {/home/manuel/Zotero/storage/HZN5NY77/review-of-deep-learning-algorithms-for-object-detection-c1f3d437b852.html}
}

@article{fuhrmannDeepLearningBilderkennungSteuerung,
  langid = {german},
  title = {Deep Learning in der BilderkennungSteuerung autonomer mobiler Roboter mit Hilfe neuronaler Netze},
  abstract = {This present bachelor thesis deals with the problem of machine learning for orientation and navigation by visual perception, based on a practical example using a robot vehicle. The basis of this thesis are deep learning concepts in artificial neural networks in the field of image recognition and the theoretical and practical comparison of training models for this networks. The usability of those methods in the context of robot navigation in dynamic environments is evaluated, using a specially for this work developed robot vehicle. Finally, the implementation of the theoretical concepts of these deep learning models is demonstrated with the practical use of this robot vehicle.},
  pages = {64},
  author = {Fuhrmann, Arno},
  file = {/home/manuel/Zotero/storage/79Q82YWZ/Fuhrmann - Deep Learning in der BilderkennungSteuerung autono.pdf}
}

@book{goodfellowDeepLearning2016a,
  location = {{Cambridge, Massachusetts}},
  title = {Deep Learning},
  isbn = {978-0-262-03561-3},
  pagetotal = {775},
  series = {Adaptive Computation and Machine Learning},
  publisher = {{The MIT Press}},
  date = {2016},
  keywords = {Machine learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  file = {/home/manuel/Zotero/storage/PIDA5GUJ/Goodfellow et al. - 2016 - Deep learning.pdf;/home/manuel/Zotero/storage/SHPR35HQ/[Bengio,_Yoshua\;_Courville,_Aaron\;_Goodfellow,_Ian(z-lib.org).pdf}
}

@book{geronHandsonMachineLearning2017,
  location = {{Beijing ; Boston}},
  title = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}}: Concepts, Tools, and Techniques to Build Intelligent Systems},
  edition = {First edition},
  isbn = {978-1-4919-6229-9},
  shorttitle = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}}},
  abstract = {"Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. By using concrete examples, minimal theory, and two production-ready Python frameworks--Scikit-Learn and TensorFlow--author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you've learned, all you need is programming experience to get started" --},
  pagetotal = {551},
  publisher = {{O'Reilly Media}},
  date = {2017},
  keywords = {Machine learning,Artificial intelligence,Automatische Klassifikation,COMPUTERS / Computer Vision & Pattern Recognition,COMPUTERS / Data Processing,COMPUTERS / Intelligence (AI) & Semantics,COMPUTERS / Natural Language Processing,COMPUTERS / Neural Networks,Künstliche Intelligenz,Maschinelles Lernen,Nonfiction,Python 3.0},
  author = {Géron, Aurélien},
  file = {/home/manuel/Zotero/storage/7G447IXE/Géron - Hands-On Machine Learning with Scikit-Learn and Te.pdf},
  note = {OCLC: ocn953432302}
}

@book{burkovHundredpageMachineLearning2019,
  langid = {english},
  title = {The Hundred-Page Machine Learning Book},
  isbn = {978-1-9995795-0-0},
  date = {2019},
  author = {Burkov, Andriy},
  file = {/home/manuel/Zotero/storage/UF5V7A3N/Burkov - 2019 - The hundred-page machine learning book.pdf},
  note = {OCLC: 1089445188}
}

@book{pattersonDeepLearningPractitioner2017,
  location = {{Sebastopol, CA}},
  title = {Deep Learning: A Practitioner's Approach},
  edition = {First edition},
  isbn = {978-1-4919-1425-0},
  shorttitle = {Deep Learning},
  abstract = {How can machine learning--especially deep neural networks--make a real difference in your organization? This hands-on guide not only provides practical information, but helps you get started building efficient deep learning networks. The authors provide the fundamentals of deep learning--tuning, parallelization, vectorization, and building pipelines--that are valid for any library before introducing the open source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, you'll learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.--},
  pagetotal = {507},
  publisher = {{O'Reilly}},
  date = {2017},
  keywords = {Machine learning,Neural networks (Computer science),Open source software},
  author = {Patterson, Josh and Gibson, Adam},
  file = {/home/manuel/Zotero/storage/PW4J26IS/Patterson and Gibson - 2017 - Deep learning a practitioner's approach.pdf},
  note = {OCLC: ocn902657832}
}

@book{osingaDeepLearningCookbook2018,
  location = {{Sebastopol, CA}},
  title = {Deep Learning Cookbook: Practical Recipes to Get Started Quickly},
  edition = {First edition},
  isbn = {978-1-4919-9584-6},
  shorttitle = {Deep Learning Cookbook},
  abstract = {Deep learning doesn't have to be intimidating. Until recently, this machine-learning method required years of study, but with frameworks such as Keras and Tensorflow, software engineers without a background in machine learning can quickly enter the field. With the recipes in this cookbook, you'll learn how to solve deep-learning problems for classifying and generating text, images, and music. Each chapter consists of several recipes needed to complete a single project, such as training a music recommending system. Author Douwe Osinga also provides a chapter with half a dozen techniques to help you if you're stuck. Examples are written in Python with code available on GitHub as a set of Python notebooks. You'll learn how to: Create applications that will serve real users; Use word embeddings to calculate text similarity; Build a movie recommender system based on Wikipedia links; Learn how AIs see the world by visualizing their internal state; Build a model to suggest emojis for pieces of text; Reuse pretrained networks to build an inverse image search service; Compare how GANs, autoencoders and LSTMs generate icons; Detect music styles and index song collections},
  pagetotal = {234},
  publisher = {{O'Reilly Media}},
  date = {2018},
  keywords = {Machine learning,Apprentissage automatique,Intelligence artificielle},
  author = {Osinga, Douwe},
  file = {/home/manuel/Zotero/storage/FH9EUA4I/Deep Learning Cookbook.epub},
  note = {OCLC: on1004763844}
}

@book{budumaFundamentalsDeepLearning2017,
  location = {{Sebastopol, CA}},
  title = {Fundamentals of Deep Learning: Designing next-Generation Machine Intelligence Algorithms},
  edition = {First edition},
  isbn = {978-1-4919-2561-4},
  shorttitle = {Fundamentals of Deep Learning},
  pagetotal = {283},
  publisher = {{O'Reilly Media}},
  date = {2017},
  keywords = {Machine learning,Artificial intelligence,Künstliche Intelligenz,Maschinelles Lernen,Neural networks (Computer science),Deep learning},
  author = {Buduma, Nikhil and Locascio, Nicholas},
  file = {/home/manuel/Zotero/storage/6JII5W6F/Buduma and Locascio - 2017 - Fundamentals of deep learning designing next-gene.pdf},
  note = {OCLC: ocn992798385}
}

@article{mainiMachineLearningHumans,
  langid = {english},
  title = {Machine {{Learning}} for {{Humans}}},
  pages = {97},
  author = {Maini, Vishal and Sabri, Samer},
  file = {/home/manuel/Zotero/storage/TKWAKJSZ/Maini and Sabri - Machine Learning for Humans.pdf}
}

@book{mckinneyPythonDataAnalysis2018,
  location = {{Sebastopol, California}},
  title = {Python for Data Analysis: Data Wrangling with Pandas, {{NumPy}}, and {{IPython}}},
  edition = {Second edition},
  isbn = {978-1-4919-5766-0},
  shorttitle = {Python for Data Analysis},
  abstract = {"Get complete instructions for manipulating, processing, cleaning, and crunching datasets in Python. Updated for Python 3.6, the second edition of this hands-on guide is packed with practical case studies that show you how to solve a broad set of data analysis problems effectively. You'll learn the latest versions of pandas, NumPy, IPython, and Jupyter in the process"--Page 4 of cover},
  pagetotal = {524},
  publisher = {{O'Reilly Media, Inc}},
  date = {2018},
  keywords = {Data mining,Data Mining,Datenanalyse,Datenmanagement,Programming languages (Electronic computers),Python (Computer program language),Python 3.6},
  author = {McKinney, Wes},
  file = {/home/manuel/Zotero/storage/C4DUDVDA/McKinney - 2018 - Python for data analysis data wrangling with pand.pdf},
  note = {OCLC: ocn959595088}
}

@book{richterSTATISTISCHESUNDMASCHINELLES2019,
  langid = {german},
  location = {{S.l.}},
  title = {STATISTISCHES UND MASCHINELLES LERNEN: gngige verfahren im berblick.},
  isbn = {978-3-662-59353-0},
  shorttitle = {STATISTISCHES UND MASCHINELLES LERNEN},
  publisher = {{SPRINGER}},
  date = {2019},
  author = {RICHTER, STEFAN},
  file = {/home/manuel/Zotero/storage/A5MEPHUU/RICHTER - 2019 - STATISTISCHES UND MASCHINELLES LERNEN gngige verf.pdf},
  note = {OCLC: 1096518028}
}

@book{ramsundarTensorFlowDeepLearning2018,
  location = {{Beijing}},
  title = {{{TensorFlow}} for Deep Learning: From Linear Regression to Reinforcement Learning},
  edition = {First edition},
  isbn = {978-1-4919-8045-3},
  shorttitle = {{{TensorFlow}} for Deep Learning},
  pagetotal = {240},
  publisher = {{O'Reilly Media}},
  date = {2018},
  keywords = {Machine learning,Artificial intelligence,Maschinelles Lernen,Lineare Regression,Neuronales Netz,Optimierung,Reinforcement learning,TensorFlow},
  author = {Ramsundar, Bharath and Zadeh, Reza Bosagh},
  file = {/home/manuel/Zotero/storage/X8L4RGBM/Ramsundar and Zadeh - 2018 - TensorFlow for deep learning from linear regressi.pdf},
  note = {OCLC: on1030582228}
}

@book{hastieElementsStatisticalLearning2009,
  langid = {English.},
  title = {The elements of statistical learning: data mining, inference and prediction},
  isbn = {9780387848570 9780387848587 9781282827264 9781282126749 9786612126741},
  url = {http://site.ebrary.com/id/10289757},
  shorttitle = {The elements of statistical learning},
  abstract = {"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for "wide'' data (p bigger than n), including multiple testing and false discovery rates."--Publisher's website.},
  urldate = {2019-12-21},
  date = {2009},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  file = {/home/manuel/Zotero/storage/S6VAIPX8/Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf},
  note = {OCLC: 1058138445}
}

@book{kirkThoughtfulMachineLearning2017,
  location = {{Beijing ; Boston}},
  title = {Thoughtful Machine Learning with {{Python}}: A Test-Driven Approach},
  edition = {First edition},
  isbn = {978-1-4919-2413-6},
  shorttitle = {Thoughtful Machine Learning with {{Python}}},
  pagetotal = {201},
  publisher = {{O'Reilly}},
  date = {2017},
  keywords = {Machine learning,Python (Computer program language)},
  author = {Kirk, Matthew},
  file = {/home/manuel/Zotero/storage/58EDQF9I/Kirk - 2017 - Thoughtful machine learning with Python a test-dr.pdf},
  note = {OCLC: ocn908375399}
}

@book{michelucciAdvancedAppliedDeep2019a,
  langid = {english},
  location = {{Berkeley, CA}},
  title = {Advanced {{Applied Deep Learning}}: {{Convolutional Neural Networks}} and {{Object Detection}}},
  isbn = {978-1-4842-4975-8 978-1-4842-4976-5},
  url = {http://link.springer.com/10.1007/978-1-4842-4976-5},
  doi = {10.1007/978-1-4842-4976-5},
  shorttitle = {Advanced {{Applied Deep Learning}}},
  publisher = {{Apress}},
  urldate = {2019-12-21},
  date = {2019},
  author = {Michelucci, Umberto},
  file = {/home/manuel/Zotero/storage/RVIKXVBL/Michelucci - 2019 - Advanced Applied Deep Learning Convolutional Neur.pdf}
}

@book{loyNeuralNetworkProjects2019,
  langid = {english},
  title = {Neural Network Projects with {{Python}}: The Ultimate Guide to Using {{Python}} to Explore the True Power of Neural Networks through Six Projects},
  isbn = {978-1-78913-890-0},
  shorttitle = {Neural Network Projects with {{Python}}},
  abstract = {"Neural networks are at the core of recent AI advances, providing some of the best resolutions to many real-world problems, including image recognition, medical diagnosis, text analysis, and more.  This book goes through some basic neural network and deep learning concepts, as well as some popular libraries in Python for implementing them."--},
  date = {2019},
  author = {Loy, James},
  file = {/home/manuel/Zotero/storage/JRKB5WGH/[Loy_James]_Neural_Network_Projects_with_Python(z-lib.org).epub},
  note = {OCLC: 1101170342}
}

@article{ramsundarCS224dTensorFlowTutorial,
  langid = {english},
  title = {{{CS224d}}: {{TensorFlow Tutorial}}},
  pages = {44},
  author = {Ramsundar, Bharath},
  file = {/home/manuel/Zotero/storage/4DC8P8YT/Ramsundar - CS224d TensorFlow Tutorial.pdf}
}

@book{PracticalComputerVision2019,
  location = {{New York, NY}},
  title = {Practical Computer Vision Applications Using Deep Learning with {{CNNs}}: With Detailed Examples in {{Python}} Using Tensorflow and Kivy},
  isbn = {978-1-4842-4166-0},
  shorttitle = {Practical Computer Vision Applications Using Deep Learning with {{CNNs}}},
  publisher = {{Springer Science+Business Media}},
  date = {2019},
  file = {/home/manuel/Zotero/storage/PHRYEAYV/2019 - Practical computer vision applications using deep .pdf}
}

@article{bhandariImageEnhancementObject2018,
  langid = {english},
  title = {Image {{Enhancement}} and {{Object Recognition}} for {{Night Vision Surveillance}}},
  abstract = {Object recognition is a critical part of any surveillance system. It is the matter of utmost concern to identify intruders and foreign objects in the area where surveillance is done. The performance of surveillance system using the traditional camera in daylight is vastly superior as compared to night. The main problem for surveillance during the night is the objects captured by traditional cameras have low contrast against the background because of the absence of ambient light in the visible spectrum. Due to that reason, the image is taken in low light condition using an Infrared Camera and the image is enhanced to obtain an image with higher contrast using different enhancing algorithms based on the spatial domain. The enhanced image is then sent to the classification process. The classification is done by using convolutional neural network followed by a fully connected layer of neurons. The accuracy of classification after implementing different enhancement algorithms is compared in this paper.},
  date = {2018},
  pages = {7},
  author = {Bhandari, Aashish and Kafle, Aayush and Dhakal, Pranjal and Joshi, Prateek Raj and Kshatri, Dinesh Baniya},
  file = {/home/manuel/Zotero/storage/M6WX4UYU/Bhandari et al. - 2018 - Image Enhancement and Object Recognition for Night.pdf}
}

@article{jangbladObjectDetectionInfrared,
  langid = {english},
  title = {Object {{Detection}} in {{Infrared Images}} Using {{Deep Convolutional Neural Networks}}},
  pages = {43},
  author = {Jangblad, Markus},
  file = {/home/manuel/Zotero/storage/7L9MMTKM/Jangblad - Object Detection in Infrared Images using Deep Con.pdf}
}

@article{nielsenNeuralNetworksDeep2015,
  langid = {english},
  title = {Neural {{Networks}} and {{Deep Learning}}},
  url = {http://neuralnetworksanddeeplearning.com},
  urldate = {2019-12-23},
  date = {2015},
  author = {Nielsen, Michael A.},
  file = {/home/manuel/Zotero/storage/FAY54QMC/neuralnetworksanddeeplearning.com.html}
}

@article{krizhevskyImageNetClassificationDeep2017,
  langid = {english},
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  volume = {60},
  issn = {00010782},
  url = {http://dl.acm.org/citation.cfm?doid=3098997.3065386},
  doi = {10.1145/3065386},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  number = {6},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  urldate = {2019-12-23},
  date = {2017-05-24},
  pages = {84-90},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  file = {/home/manuel/Zotero/storage/57ECAJX5/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf}
}

@online{CS231nConvolutionalNeural,
  title = {{{CS231n Convolutional Neural Networks}} for {{Visual Recognition}}},
  url = {http://cs231n.github.io/},
  urldate = {2019-12-25},
  file = {/home/manuel/Zotero/storage/SHX5VT3N/cs231n.github.io.html}
}

@article{renFasterRCNNRealTime2016,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1506.01497},
  primaryClass = {cs},
  title = {Faster {{R}}-{{CNN}}: {{Towards Real}}-{{Time Object Detection}} with {{Region Proposal Networks}}},
  url = {http://arxiv.org/abs/1506.01497},
  shorttitle = {Faster {{R}}-{{CNN}}},
  abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
  urldate = {2019-12-25},
  date = {2016-01-06},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  file = {/home/manuel/Zotero/storage/YUNVEGBM/Ren et al. - 2016 - Faster R-CNN Towards Real-Time Object Detection w.pdf;/home/manuel/Zotero/storage/ASDDJ3A3/1506.html}
}

@incollection{snoekPracticalBayesianOptimization2012,
  title = {Practical {{Bayesian Optimization}} of {{Machine Learning Algorithms}}},
  url = {http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf},
  booktitle = {Advances in {{Neural Information Processing Systems}} 25},
  publisher = {{Curran Associates, Inc.}},
  urldate = {2019-12-25},
  date = {2012},
  pages = {2951--2959},
  author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  file = {/home/manuel/Zotero/storage/G463P3LP/Snoek et al. - 2012 - Practical Bayesian Optimization of Machine Learnin.pdf;/home/manuel/Zotero/storage/6YLF3IMX/4522-practical-bayesian-optimization-of-machine-learning-algorithms.html}
}

@online{MachineLearningGlossary,
  title = {Machine {{Learning Glossary}} — {{ML Glossary}} Documentation},
  url = {https://ml-cheatsheet.readthedocs.io/en/latest/},
  urldate = {2019-12-25},
  file = {/home/manuel/Zotero/storage/MGRC5GMS/latest.html}
}

@article{lecunDeepLearning2015,
  langid = {english},
  title = {Deep Learning},
  volume = {521},
  issn = {0028-0836, 1476-4687},
  url = {http://www.nature.com/articles/nature14539},
  doi = {10.1038/nature14539},
  number = {7553},
  journaltitle = {Nature},
  shortjournal = {Nature},
  urldate = {2019-12-25},
  date = {2015-05},
  pages = {436-444},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  file = {/home/manuel/Zotero/storage/DBBPWJZB/LeCun et al. - 2015 - Deep learning.pdf}
}

@online{ConfusionMatrixMlxtend,
  title = {Confusion {{Matrix}} - Mlxtend},
  url = {https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix/},
  urldate = {2019-12-25},
  file = {/home/manuel/Zotero/storage/64QURGBJ/confusion_matrix.html}
}

@online{SimpleGuideConfusion2014,
  langid = {english},
  title = {Simple Guide to Confusion Matrix Terminology},
  url = {https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/},
  abstract = {A confusion matrix is a table that is often used to describe the performance of a classification model (or "classifier") on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be...},
  journaltitle = {Data School},
  urldate = {2019-12-25},
  date = {2014-03-26T03:41:42.000Z},
  file = {/home/manuel/Zotero/storage/EIEL6HET/simple-guide-to-confusion-matrix-terminology.html}
}

@online{sheffieldFirstSteps,
  langid = {english},
  title = {First Steps},
  url = {http://sheffieldml.github.io/GPyOpt/firstexamples/},
  abstract = {GPyOpt is a user friendly framework with two interfaces},
  urldate = {2019-12-25},
  author = {of Sheffield, Machine Learning Group-University},
  file = {/home/manuel/Zotero/storage/84Y5R2NV/index.html}
}

@book{cholletDeepLearningPython2018,
  location = {{Shelter Island, New York}},
  title = {Deep Learning with {{Python}}},
  isbn = {978-1-61729-443-3},
  pagetotal = {361},
  publisher = {{Manning Publications Co}},
  date = {2018},
  keywords = {Machine learning,Neural networks (Computer science),Python (Computer program language)},
  author = {Chollet, François},
  file = {/home/manuel/Zotero/storage/6LHCX86B/Chollet - 2018 - Deep learning with Python.pdf},
  note = {OCLC: ocn982650571}
}

@article{srivastavaDropoutSimpleWay,
  langid = {english},
  title = {Dropout: {{A Simple Way}} to {{Prevent Neural Networks}} from {{Overﬁtting}}},
  abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
  pages = {30},
  author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  file = {/home/manuel/Zotero/storage/YXWYZZM9/Srivastava et al. - Dropout A Simple Way to Prevent Neural Networks f.pdf}
}

@misc{OIDv4_ToolKit,
  title={Toolkit to download and visualize single or multiple classes from the huge Open Images v4 dataset},
  author={Vittorio, Angelo},
  year={2018},
  publisher={Github},
  journal={GitHub repository},
  howpublished={\url{https://github.com/EscVM/OIDv4_ToolKit}},
}


