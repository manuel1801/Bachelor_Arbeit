
@article{amidiSuperVIPCheatsheet2019,
  title = {Super {{VIP Cheatsheet}}: {{Deep Learning}}},
  author = {Amidi, Shervine and Amidi, Afshine},
  date = {2019},
  journaltitle = {Deep Learning},
  pages = {13},
  file = {/home/manuel/Zotero/storage/8FXHT8JQ/super-cheatsheet-machine-learning.pdf;/home/manuel/Zotero/storage/T8PRDR6B/Amidi and Amidi - 2019 - Super VIP Cheatsheet Deep Learning.pdf},
  langid = {english}
}

@book{budumaFundamentalsDeepLearning2017,
  title = {Fundamentals of Deep Learning: Designing next-Generation Machine Intelligence Algorithms},
  shorttitle = {Fundamentals of Deep Learning},
  author = {Buduma, Nikhil and Locascio, Nicholas},
  date = {2017},
  edition = {First edition},
  publisher = {{O'Reilly Media}},
  location = {{Sebastopol, CA}},
  file = {/home/manuel/Zotero/storage/6JII5W6F/Buduma and Locascio - 2017 - Fundamentals of deep learning designing next-gene.pdf},
  isbn = {978-1-4919-2561-4},
  keywords = {Artificial intelligence,Deep learning,Künstliche Intelligenz,Machine learning,Maschinelles Lernen,Neural networks (Computer science)},
  note = {OCLC: ocn992798385},
  pagetotal = {283}
}

@book{burkovHundredpageMachineLearning2019,
  title = {The Hundred-Page Machine Learning Book},
  author = {Burkov, Andriy},
  date = {2019},
  file = {/home/manuel/Zotero/storage/UF5V7A3N/Burkov - 2019 - The hundred-page machine learning book.pdf},
  isbn = {978-1-9995795-0-0},
  langid = {english},
  note = {OCLC: 1089445188}
}

@book{cholletDeepLearningPython2018,
  title = {Deep Learning with {{Python}}},
  author = {Chollet, François},
  date = {2018},
  publisher = {{Manning Publications Co}},
  location = {{Shelter Island, New York}},
  file = {/home/manuel/Zotero/storage/6LHCX86B/Chollet - 2018 - Deep learning with Python.pdf},
  isbn = {978-1-61729-443-3},
  keywords = {Machine learning,Neural networks (Computer science),Python (Computer program language)},
  note = {OCLC: ocn982650571},
  pagetotal = {361}
}

@artwork{Docs,
  title = {Docs}
}

@article{fuhrmannDeepLearningBilderkennungSteuerung,
  title = {Deep Learning in der BilderkennungSteuerung autonomer mobiler Roboter mit Hilfe neuronaler Netze},
  author = {Fuhrmann, Arno},
  pages = {64},
  abstract = {This present bachelor thesis deals with the problem of machine learning for orientation and navigation by visual perception, based on a practical example using a robot vehicle. The basis of this thesis are deep learning concepts in artificial neural networks in the field of image recognition and the theoretical and practical comparison of training models for this networks. The usability of those methods in the context of robot navigation in dynamic environments is evaluated, using a specially for this work developed robot vehicle. Finally, the implementation of the theoretical concepts of these deep learning models is demonstrated with the practical use of this robot vehicle.},
  file = {/home/manuel/Zotero/storage/79Q82YWZ/Fuhrmann - Deep Learning in der BilderkennungSteuerung autono.pdf},
  langid = {german}
}

@online{geitgeyMachineLearningFun,
  title = {Machine {{Learning}} Is {{Fun}}!},
  author = {Geitgey, Adam}
}

@book{geronHandsonMachineLearning2017,
  title = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}}: Concepts, Tools, and Techniques to Build Intelligent Systems},
  shorttitle = {Hands-on Machine Learning with {{Scikit}}-{{Learn}} and {{TensorFlow}}},
  author = {Géron, Aurélien},
  date = {2017},
  edition = {First edition},
  publisher = {{O'Reilly Media}},
  location = {{Beijing ; Boston}},
  abstract = {"Through a series of recent breakthroughs, deep learning has boosted the entire field of machine learning. Now, even programmers who know close to nothing about this technology can use simple, efficient tools to implement programs capable of learning from data. This practical book shows you how. By using concrete examples, minimal theory, and two production-ready Python frameworks--Scikit-Learn and TensorFlow--author Aurélien Géron helps you gain an intuitive understanding of the concepts and tools for building intelligent systems. You'll learn a range of techniques, starting with simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what you've learned, all you need is programming experience to get started" --},
  file = {/home/manuel/Zotero/storage/7G447IXE/Géron - Hands-On Machine Learning with Scikit-Learn and Te.pdf},
  isbn = {978-1-4919-6229-9},
  keywords = {Artificial intelligence,Automatische Klassifikation,COMPUTERS / Computer Vision & Pattern Recognition,COMPUTERS / Data Processing,COMPUTERS / Intelligence (AI) & Semantics,COMPUTERS / Natural Language Processing,COMPUTERS / Neural Networks,Künstliche Intelligenz,Machine learning,Maschinelles Lernen,Nonfiction,Python 3.0},
  note = {OCLC: ocn953432302},
  pagetotal = {551}
}

@book{goodfellowDeepLearning2016a,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  file = {/home/manuel/Zotero/storage/PIDA5GUJ/Goodfellow et al. - 2016 - Deep learning.pdf;/home/manuel/Zotero/storage/SHPR35HQ/[Bengio,_Yoshua\;_Courville,_Aaron\;_Goodfellow,_Ian(z-lib.org).pdf},
  isbn = {978-0-262-03561-3},
  keywords = {Machine learning},
  pagetotal = {775},
  series = {Adaptive Computation and Machine Learning}
}

@article{hasibiAugmentationSchemeDealing2019,
  title = {Augmentation {{Scheme}} for {{Dealing}} with {{Imbalanced Network Traffic Classification Using Deep Learning}}},
  author = {Hasibi, Ramin and Shokri, Matin and Dehghan, Mehdi},
  date = {2019-01-01},
  url = {http://arxiv.org/abs/1901.00204},
  urldate = {2020-01-30},
  abstract = {One of the most important tasks in network management is identifying different types of traffic flows. As a result, a type of management service, called Network Traffic Classifier (NTC), has been introduced. One type of NTCs that has gained huge attention in recent years applies deep learning on packets in order to classify flows. Internet is an imbalanced environment i.e., some classes of applications are a lot more populated than others e.g., HTTP. Additionally, one of the challenges in deep learning methods is that they do not perform well in imbalanced environments in terms of evaluation metrics such as precision, recall, and F1 measure. In order to solve this problem, we recommend the use of augmentation methods to balance the dataset. In this paper, we propose a novel data augmentation approach based on the use of Long Short Term Memory (LSTM) networks for generating traffic flow patterns and Kernel Density Estimation (KDE) for replicating the numerical features of each class. First, we use the LSTM network in order to learn and generate the sequence of packets in a flow for classes with less population. Then, we complete the features of the sequence with generating random values based on the distribution of a certain feature, which will be estimated using KDE. Finally, we compare the training of a Convolutional Recurrent Neural Network (CRNN) in large-scale imbalanced, sampled, and augmented datasets. The contribution of our augmentation scheme is then evaluated on all of the datasets through measurements of precision, recall, and F1 measure for every class of application. The results demonstrate that our scheme is well suited for network traffic flow datasets and improves the performance of deep learning algorithms when it comes to above-mentioned metrics.},
  archivePrefix = {arXiv},
  eprint = {1901.00204},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/N2A2R3ZV/Hasibi et al. - 2019 - Augmentation Scheme for Dealing with Imbalanced Ne.pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Networking and Internet Architecture},
  langid = {english},
  primaryClass = {cs}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The elements of statistical learning: data mining, inference and prediction},
  shorttitle = {The elements of statistical learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2009},
  url = {http://site.ebrary.com/id/10289757},
  urldate = {2019-12-21},
  abstract = {"During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for "wide'' data (p bigger than n), including multiple testing and false discovery rates."--Publisher's website.},
  file = {/home/manuel/Zotero/storage/S6VAIPX8/Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf},
  isbn = {9780387848570 9780387848587 9781282827264 9781282126749 9786612126741},
  langid = {English.},
  note = {OCLC: 1058138445}
}

@thesis{haussermannFunktionUndEffizienz,
  title = {Funktion Und {{Effizienz}} von {{Hardware}} Für {{Deep Neural Networks}}},
  author = {Häußermann, Marvin},
  file = {/home/manuel/Zotero/storage/EN3J5YAX/Häußermann - Funktion und Effizienz von Hardware für Deep Neura.pdf}
}

@online{HttpsGithubCom,
  title = {{{https://github.com/tensorflow/models/tree/master/research/object\_detection}}},
  url = {https://github.com/tensorflow/models/tree/master/research/object_detection}
}

@inproceedings{huangSpeedAccuracyTradeOffs2017,
  title = {Speed/{{Accuracy Trade}}-{{Offs}} for {{Modern Convolutional Object Detectors}}},
  booktitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Huang, Jonathan and Rathod, Vivek and Sun, Chen and Zhu, Menglong and Korattikara, Anoop and Fathi, Alireza and Fischer, Ian and Wojna, Zbigniew and Song, Yang and Guadarrama, Sergio and Murphy, Kevin},
  date = {2017-07},
  pages = {3296--3297},
  publisher = {{IEEE}},
  location = {{Honolulu, HI}},
  doi = {10.1109/CVPR.2017.351},
  url = {http://ieeexplore.ieee.org/document/8099834/},
  urldate = {2020-01-30},
  abstract = {The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform. To this end, we investigate various ways to trade accuracy for speed and memory usage in modern convolutional object detection systems. A number of successful systems have been proposed in recent years, but apples-toapples comparisons are difficult due to different base feature extractors (e.g., VGG, Residual Networks), different default image resolutions, as well as different hardware and software platforms. We present a unified implementation of the Faster R-CNN [31], R-FCN [6] and SSD [26] systems, which we view as “meta-architectures” and trace out the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures. On one extreme end of this spectrum where speed and memory are critical, we present a detector that achieves real time speeds and can be deployed on a mobile device. On the opposite end in which accuracy is critical, we present a detector that achieves state-of-the-art performance measured on the COCO detection task.},
  eventtitle = {2017 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  file = {/home/manuel/Zotero/storage/NDWSQVIR/Huang et al. - 2017 - SpeedAccuracy Trade-Offs for Modern Convolutional.pdf},
  isbn = {978-1-5386-0457-1},
  langid = {english}
}

@online{huiObjectDetectionSeries,
  title = {Object {{Detection Series}}},
  author = {Hui, Jonathan}
}

@online{ImageNetLargeScale,
  title = {{{ImageNet Large Scale Visual Recognition Competition}} ({{ILSVRC}})},
  url = {http://www.image-net.org/challenges/LSVRC/},
  urldate = {2020-02-02},
  file = {/home/manuel/Zotero/storage/PYYYF6UC/LSVRC.html}
}

@article{jangbladObjectDetectionInfrared,
  title = {Object {{Detection}} in {{Infrared Images}} Using {{Deep Convolutional Neural Networks}}},
  author = {Jangblad, Markus},
  pages = {43},
  file = {/home/manuel/Zotero/storage/7L9MMTKM/Jangblad - Object Detection in Infrared Images using Deep Con.pdf},
  langid = {english}
}

@online{jordanCommonArchitecturesConvolutional,
  title = {Common Architectures in Convolutional Neural Networks},
  author = {Jordan, Jeremy}
}

@article{kellenbergerDetectingMammalsUAV2018,
  title = {Detecting {{Mammals}} in {{UAV Images}}: {{Best Practices}} to Address a Substantially {{Imbalanced Dataset}} with {{Deep Learning}}},
  shorttitle = {Detecting {{Mammals}} in {{UAV Images}}},
  author = {Kellenberger, Benjamin and Marcos, Diego and Tuia, Devis},
  date = {2018-10},
  journaltitle = {Remote Sensing of Environment},
  shortjournal = {Remote Sensing of Environment},
  volume = {216},
  pages = {139--153},
  issn = {00344257},
  doi = {10.1016/j.rse.2018.06.028},
  url = {http://arxiv.org/abs/1806.11368},
  urldate = {2020-02-01},
  abstract = {Knowledge over the number of animals in large wildlife reserves is a vital necessity for park rangers in their efforts to protect endangered species. Manual animal censuses are dangerous and expensive, hence Unmanned Aerial Vehicles (UAVs) with consumer level digital cameras are becoming a popular alternative tool to estimate livestock. Several works have been proposed that semi-automatically process UAV images to detect animals, of which some employ Convolutional Neural Networks (CNNs), a recent family of deep learning algorithms that proved very effective in object detection in large datasets from computer vision. However, the majority of works related to wildlife focuses only on small datasets (typically subsets of UAV campaigns), which might be detrimental when presented with the sheer scale of real study areas for large mammal census. Methods may yield thousands of false alarms in such cases. In this paper, we study how to scale CNNs to large wildlife census tasks and present a number of recommendations to train a CNN on a large UAV dataset. We further introduce novel evaluation protocols that are tailored to censuses and model suitability for subsequent human verification of detections. Using our recommendations, we are able to train a CNN reducing the number of false positives by an order of magnitude compared to previous state-of-the-art. Setting the requirements at 90\% recall, our CNN allows to reduce the amount of data required for manual verification by three times, thus making it possible for rangers to screen all the data acquired efficiently and to detect almost all animals in the reserve automatically.},
  archivePrefix = {arXiv},
  eprint = {1806.11368},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/GTPSDAUC/Kellenberger et al. - 2018 - Detecting Mammals in UAV Images Best Practices to.pdf;/home/manuel/Zotero/storage/YIK9D2IU/1806.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@book{kirkThoughtfulMachineLearning2017,
  title = {Thoughtful Machine Learning with {{Python}}: A Test-Driven Approach},
  shorttitle = {Thoughtful Machine Learning with {{Python}}},
  author = {Kirk, Matthew},
  date = {2017},
  edition = {First edition},
  publisher = {{O'Reilly}},
  location = {{Beijing ; Boston}},
  file = {/home/manuel/Zotero/storage/58EDQF9I/Kirk - 2017 - Thoughtful machine learning with Python a test-dr.pdf},
  isbn = {978-1-4919-2413-6},
  keywords = {Machine learning,Python (Computer program language)},
  note = {OCLC: ocn908375399},
  pagetotal = {201}
}

@article{krizhevskyImageNetClassificationDeep2017a,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  pages = {84--90},
  issn = {00010782},
  doi = {10.1145/3065386},
  url = {http://dl.acm.org/citation.cfm?doid=3098997.3065386},
  urldate = {2020-01-30},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  file = {/home/manuel/Zotero/storage/VK8QT4GD/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf},
  langid = {english},
  number = {6}
}

@article{kuznetsovaOpenImagesDataset2018,
  title = {The {{Open Images Dataset V4}}: {{Unified}} Image Classification, Object Detection, and Visual Relationship Detection at Scale},
  shorttitle = {The {{Open Images Dataset V4}}},
  author = {Kuznetsova, Alina and Rom, Hassan and Alldrin, Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali, Shahab and Popov, Stefan and Malloci, Matteo and Duerig, Tom and Ferrari, Vittorio},
  date = {2018-11-02},
  url = {http://arxiv.org/abs/1811.00982},
  urldate = {2020-02-02},
  abstract = {We present Open Images V4, a dataset of 9.2M images with unified annotations for image classification, object detection and visual relationship detection. The images have a Creative Commons Attribution license that allows to share and adapt the material, and they have been collected from Flickr without a predefined list of class names or tags, leading to natural class statistics and avoiding an initial design bias. Open Images V4 offers large scale across several dimensions: 30.1M image-level labels for 19.8k concepts, 15.4M bounding boxes for 600 object classes, and 375k visual relationship annotations involving 57 classes. For object detection in particular, we provide 15x more bounding boxes than the next largest datasets (15.4M boxes on 1.9M images). The images often show complex scenes with several objects (8 annotated objects per image on average). We annotated visual relationships between them, which support visual relationship detection, an emerging task that requires structured reasoning. We provide in-depth comprehensive statistics about the dataset, we validate the quality of the annotations, and we study how the performance of many modern models evolves with increasing amounts of training data. We hope that the scale, quality, and variety of Open Images V4 will foster further research and innovation even beyond the areas of image classification, object detection, and visual relationship detection.},
  archivePrefix = {arXiv},
  eprint = {1811.00982},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/AL4TJUF3/Kuznetsova et al. - 2018 - The Open Images Dataset V4 Unified image classifi.pdf;/home/manuel/Zotero/storage/QQ3V2IYR/1811.html},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  primaryClass = {cs}
}

@article{lecunGradientBasedLearningApplied1998,
  title = {Gradient-{{Based Learning Applied}} to {{Document Recognition}}},
  author = {LeCun, Yann and Bottou, Leon and Bengio, Yoshua and Ha, Patrick},
  date = {1998},
  pages = {46},
  file = {/home/manuel/Zotero/storage/YZLANXUV/LeCun et al. - 1998 - Gradient-Based Learning Applied to Document Recogn.pdf},
  langid = {english}
}

@book{loyNeuralNetworkProjects2019,
  title = {Neural Network Projects with {{Python}}: The Ultimate Guide to Using {{Python}} to Explore the True Power of Neural Networks through Six Projects},
  shorttitle = {Neural Network Projects with {{Python}}},
  author = {Loy, James},
  date = {2019},
  abstract = {"Neural networks are at the core of recent AI advances, providing some of the best resolutions to many real-world problems, including image recognition, medical diagnosis, text analysis, and more.  This book goes through some basic neural network and deep learning concepts, as well as some popular libraries in Python for implementing them."--},
  file = {/home/manuel/Zotero/storage/JRKB5WGH/[Loy_James]_Neural_Network_Projects_with_Python(z-lib.org).epub},
  isbn = {978-1-78913-890-0},
  langid = {english},
  note = {OCLC: 1101170342}
}

@article{mainiMachineLearningHumans,
  title = {Machine {{Learning}} for {{Humans}}},
  author = {Maini, Vishal and Sabri, Samer},
  pages = {97},
  file = {/home/manuel/Zotero/storage/TKWAKJSZ/Maini and Sabri - Machine Learning for Humans.pdf},
  langid = {english}
}

@book{mckinneyPythonDataAnalysis2018,
  title = {Python for Data Analysis: Data Wrangling with Pandas, {{NumPy}}, and {{IPython}}},
  shorttitle = {Python for Data Analysis},
  author = {McKinney, Wes},
  date = {2018},
  edition = {Second edition},
  publisher = {{O'Reilly Media, Inc}},
  location = {{Sebastopol, California}},
  abstract = {"Get complete instructions for manipulating, processing, cleaning, and crunching datasets in Python. Updated for Python 3.6, the second edition of this hands-on guide is packed with practical case studies that show you how to solve a broad set of data analysis problems effectively. You'll learn the latest versions of pandas, NumPy, IPython, and Jupyter in the process"--Page 4 of cover},
  file = {/home/manuel/Zotero/storage/C4DUDVDA/McKinney - 2018 - Python for data analysis data wrangling with pand.pdf},
  isbn = {978-1-4919-5766-0},
  keywords = {Data mining,Data Mining,Datenanalyse,Datenmanagement,Programming languages (Electronic computers),Python (Computer program language),Python 3.6},
  note = {OCLC: ocn959595088},
  pagetotal = {524}
}

@book{michelucciAdvancedAppliedDeep2019b,
  title = {Advanced {{Applied Deep Learning}}: {{Convolutional Neural Networks}} and {{Object Detection}}},
  shorttitle = {Advanced {{Applied Deep Learning}}},
  author = {Michelucci, Umberto},
  date = {2019},
  publisher = {{Apress}},
  location = {{Berkeley, CA}},
  doi = {10.1007/978-1-4842-4976-5},
  url = {http://link.springer.com/10.1007/978-1-4842-4976-5},
  urldate = {2020-02-02},
  file = {/home/manuel/Zotero/storage/RUU3TAGR/Michelucci - 2019 - Advanced Applied Deep Learning Convolutional Neur.pdf},
  isbn = {978-1-4842-4975-8 978-1-4842-4976-5},
  langid = {english}
}

@article{MLCheatsheetDocumentation,
  title = {{{ML Cheatsheet Documentation}}},
  pages = {201},
  file = {/home/manuel/Zotero/storage/PMXJY88D/ML Cheatsheet Documentation.pdf},
  langid = {english}
}

@inproceedings{nguyenAnimalRecognitionIdentification2017a,
  title = {Animal {{Recognition}} and {{Identification}} with {{Deep Convolutional Neural Networks}} for {{Automated Wildlife Monitoring}}},
  booktitle = {2017 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  author = {Nguyen, Hung and Maclagan, Sarah J. and Nguyen, Tu Dinh and Nguyen, Thin and Flemons, Paul and Andrews, Kylie and Ritchie, Euan G. and Phung, Dinh},
  date = {2017-10},
  pages = {40--49},
  publisher = {{IEEE}},
  location = {{Tokyo, Japan}},
  doi = {10.1109/DSAA.2017.31},
  url = {http://ieeexplore.ieee.org/document/8259762/},
  urldate = {2020-01-30},
  abstract = {Efficient and reliable monitoring of wild animals in their natural habitats is essential to inform conservation and management decisions. Automatic covert cameras or “camera traps” are being an increasingly popular tool for wildlife monitoring due to their effectiveness and reliability in collecting data of wildlife unobtrusively, continuously and in large volume. However, processing such a large volume of images and videos captured from camera traps manually is extremely expensive, time-consuming and also monotonous. This presents a major obstacle to scientists and ecologists to monitor wildlife in an open environment. Leveraging on recent advances in deep learning techniques in computer vision, we propose in this paper a framework to build automated animal recognition in the wild, aiming at an automated wildlife monitoring system. In particular, we use a single-labeled dataset from Wildlife Spotter project, done by citizen scientists, and the state-of-the-art deep convolutional neural network architectures, to train a computational system capable of filtering animal images and identifying species automatically. Our experimental results achieved an accuracy at 96.6\% for the task of detecting images containing animal, and 90.4\% for identifying the three most common species among the set of images of wild animals taken in South-central Victoria, Australia, demonstrating the feasibility of building fully automated wildlife observation. This, in turn, can therefore speed up research findings, construct more efficient citizen sciencebased monitoring systems and subsequent management decisions, having the potential to make significant impacts to the world of ecology and trap camera images analysis.},
  eventtitle = {2017 {{IEEE International Conference}} on {{Data Science}} and {{Advanced Analytics}} ({{DSAA}})},
  file = {/home/manuel/Zotero/storage/9C2LBIMI/Nguyen et al. - 2017 - Animal Recognition and Identification with Deep Co.pdf},
  isbn = {978-1-5090-5004-8},
  langid = {english}
}

@book{nielsenNeuralNetworksDeep,
  title = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Nielsen, Michael}
}

@online{ObjectDetectionPart2018a,
  title = {Object {{Detection Part}} 4: {{Fast Detection Models}}},
  shorttitle = {Object {{Detection Part}} 4},
  date = {2018-12-27T12:00:00+00:00},
  journaltitle = {Lil'Log},
  url = {https://lilianweng.github.io/2018/12/27/object-detection-part-4.html},
  urldate = {2020-01-27},
  abstract = {Part 4 of the “Object Detection for Dummies” series focuses on one-stage models for fast detection, including SSD, RetinaNet, and models in the YOLO family. These models skip the explicit region proposal stage but apply the detection directly on dense sampled areas.},
  file = {/home/manuel/Zotero/storage/F3VXQVFL/object-detection-part-4.html},
  langid = {english}
}

@article{oksuzImbalanceProblemsObject2020,
  title = {Imbalance {{Problems}} in {{Object Detection}}: {{A Review}}},
  shorttitle = {Imbalance {{Problems}} in {{Object Detection}}},
  author = {Oksuz, Kemal and Cam, Baris Can and Kalkan, Sinan and Akbas, Emre},
  date = {2020-01-20},
  url = {http://arxiv.org/abs/1909.00169},
  urldate = {2020-01-30},
  abstract = {In this paper, we present a comprehensive review of the imbalance problems in object detection. To analyze the problems in a systematic manner, we introduce two taxonomies; one for the problems and the other for the proposed solutions. Following the taxonomy for the problems, we discuss each problem in depth and present a unifying yet critical perspective on the solutions in the literature. In addition, we identify major open issues regarding the existing imbalance problems as well as imbalance problems that have not been discussed before. Moreover, in order to keep our review up to date, we provide an accompanying webpage which categorizes papers addressing imbalance problems, according to our problem-based taxonomy. Researchers can track newer studies on this webpage available at: https://github.com/kemaloksuz/ObjectDetectionImbalance.},
  archivePrefix = {arXiv},
  eprint = {1909.00169},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/A3VFRYKA/Oksuz et al. - 2020 - Imbalance Problems in Object Detection A Review.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryClass = {cs}
}

@online{OpenImagesDataset,
  title = {Open {{Images Dataset V5}}},
  url = {https://storage.googleapis.com/openimages/web/index.html},
  urldate = {2020-02-02},
  file = {/home/manuel/Zotero/storage/9RNZFLU6/index.html}
}

@book{osingaDeepLearningCookbook2018,
  title = {Deep Learning Cookbook: Practical Recipes to Get Started Quickly},
  shorttitle = {Deep Learning Cookbook},
  author = {Osinga, Douwe},
  date = {2018},
  edition = {First edition},
  publisher = {{O'Reilly Media}},
  location = {{Sebastopol, CA}},
  abstract = {Deep learning doesn't have to be intimidating. Until recently, this machine-learning method required years of study, but with frameworks such as Keras and Tensorflow, software engineers without a background in machine learning can quickly enter the field. With the recipes in this cookbook, you'll learn how to solve deep-learning problems for classifying and generating text, images, and music. Each chapter consists of several recipes needed to complete a single project, such as training a music recommending system. Author Douwe Osinga also provides a chapter with half a dozen techniques to help you if you're stuck. Examples are written in Python with code available on GitHub as a set of Python notebooks. You'll learn how to: Create applications that will serve real users; Use word embeddings to calculate text similarity; Build a movie recommender system based on Wikipedia links; Learn how AIs see the world by visualizing their internal state; Build a model to suggest emojis for pieces of text; Reuse pretrained networks to build an inverse image search service; Compare how GANs, autoencoders and LSTMs generate icons; Detect music styles and index song collections},
  file = {/home/manuel/Zotero/storage/FH9EUA4I/Deep Learning Cookbook.epub},
  isbn = {978-1-4919-9584-6},
  keywords = {Apprentissage automatique,Intelligence artificielle,Machine learning},
  note = {OCLC: on1004763844},
  pagetotal = {234}
}

@online{ouaknineReviewDeepLearning,
  title = {Review of {{Deep Learning Algorithms}} for {{Object Detection}}},
  author = {Ouaknine, Arthur}
}

@book{pattersonDeepLearningPractitioner2017,
  title = {Deep Learning: A Practitioner's Approach},
  shorttitle = {Deep Learning},
  author = {Patterson, Josh and Gibson, Adam},
  date = {2017},
  edition = {First edition},
  publisher = {{O'Reilly}},
  location = {{Sebastopol, CA}},
  abstract = {How can machine learning--especially deep neural networks--make a real difference in your organization? This hands-on guide not only provides practical information, but helps you get started building efficient deep learning networks. The authors provide the fundamentals of deep learning--tuning, parallelization, vectorization, and building pipelines--that are valid for any library before introducing the open source Deeplearning4j (DL4J) library for developing production-class workflows. Through real-world examples, you'll learn methods and strategies for training deep network architectures and running deep learning workflows on Spark and Hadoop with DL4J.--},
  file = {/home/manuel/Zotero/storage/PW4J26IS/Patterson and Gibson - 2017 - Deep learning a practitioner's approach.pdf},
  isbn = {978-1-4919-1425-0},
  keywords = {Machine learning,Neural networks (Computer science),Open source software},
  note = {OCLC: ocn902657832},
  pagetotal = {507}
}

@online{PersonalNotesDeep,
  title = {[{{Personal Notes}}] {{Deep Learning}} by {{Andrew Ng}}}
}

@incollection{ponceDatasetIssuesObject2006a,
  title = {Dataset {{Issues}} in {{Object Recognition}}},
  booktitle = {Toward {{Category}}-{{Level Object Recognition}}},
  author = {Ponce, J. and Berg, T. L. and Everingham, M. and Forsyth, D. A. and Hebert, M. and Lazebnik, S. and Marszalek, M. and Schmid, C. and Russell, B. C. and Torralba, A. and Williams, C. K. I. and Zhang, J. and Zisserman, A.},
  editor = {Ponce, Jean and Hebert, Martial and Schmid, Cordelia and Zisserman, Andrew},
  date = {2006},
  volume = {4170},
  pages = {29--48},
  publisher = {{Springer Berlin Heidelberg}},
  location = {{Berlin, Heidelberg}},
  doi = {10.1007/11957959_2},
  url = {http://link.springer.com/10.1007/11957959_2},
  urldate = {2020-01-30},
  abstract = {Appropriate datasets are required at all stages of object recognition research, including learning visual models of object and scene categories, detecting and localizing instances of these models in images, and evaluating the performance of recognition algorithms. Current datasets are lacking in several respects, and this paper discusses some of the lessons learned from existing efforts, as well as innovative ways to obtain very large and diverse annotated datasets. It also suggests a few criteria for gathering future datasets.},
  editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editorbtype = {redactor},
  file = {/home/manuel/Zotero/storage/LQTLYNWA/Ponce et al. - 2006 - Dataset Issues in Object Recognition.pdf},
  isbn = {978-3-540-68794-8 978-3-540-68795-5},
  langid = {english}
}

@book{PracticalComputerVision2019,
  title = {Practical Computer Vision Applications Using Deep Learning with {{CNNs}}: With Detailed Examples in {{Python}} Using Tensorflow and Kivy},
  shorttitle = {Practical Computer Vision Applications Using Deep Learning with {{CNNs}}},
  date = {2019},
  publisher = {{Springer Science+Business Media}},
  location = {{New York, NY}},
  file = {/home/manuel/Zotero/storage/PHRYEAYV/2019 - Practical computer vision applications using deep .pdf},
  isbn = {978-1-4842-4166-0}
}

@book{ramsundarTensorFlowDeepLearning2018,
  title = {{{TensorFlow}} for Deep Learning: From Linear Regression to Reinforcement Learning},
  shorttitle = {{{TensorFlow}} for Deep Learning},
  author = {Ramsundar, Bharath and Zadeh, Reza Bosagh},
  date = {2018},
  edition = {First edition},
  publisher = {{O'Reilly Media}},
  location = {{Beijing}},
  file = {/home/manuel/Zotero/storage/X8L4RGBM/Ramsundar and Zadeh - 2018 - TensorFlow for deep learning from linear regressi.pdf},
  isbn = {978-1-4919-8045-3},
  keywords = {Artificial intelligence,Lineare Regression,Machine learning,Maschinelles Lernen,Neuronales Netz,Optimierung,Reinforcement learning,TensorFlow},
  note = {OCLC: on1030582228},
  pagetotal = {240}
}

@online{RecentAdvancesDeep,
  title = {Recent {{Advances}} in {{Deep Learning}} for {{Object Detection}}}
}

@article{renFasterRCNNRealTime2016a,
  title = {Faster {{R}}-{{CNN}}: {{Towards Real}}-{{Time Object Detection}} with {{Region Proposal Networks}}},
  shorttitle = {Faster {{R}}-{{CNN}}},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  date = {2016-01-06},
  url = {http://arxiv.org/abs/1506.01497},
  urldate = {2020-01-30},
  abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with “attention” mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
  archivePrefix = {arXiv},
  eprint = {1506.01497},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/6WE6YLHU/Ren et al. - 2016 - Faster R-CNN Towards Real-Time Object Detection w.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryClass = {cs}
}

@book{richterSTATISTISCHESUNDMASCHINELLES2019,
  title = {STATISTISCHES UND MASCHINELLES LERNEN: gngige verfahren im berblick.},
  shorttitle = {STATISTISCHES UND MASCHINELLES LERNEN},
  author = {RICHTER, STEFAN},
  date = {2019},
  publisher = {{SPRINGER}},
  location = {{S.l.}},
  file = {/home/manuel/Zotero/storage/A5MEPHUU/RICHTER - 2019 - STATISTISCHES UND MASCHINELLES LERNEN gngige verf.pdf},
  isbn = {978-3-662-59353-0},
  langid = {german},
  note = {OCLC: 1096518028}
}

@article{russakovskyImageNetLargeScale2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
  date = {2015-01-29},
  url = {http://arxiv.org/abs/1409.0575},
  urldate = {2020-02-02},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
  archivePrefix = {arXiv},
  eprint = {1409.0575},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/RIXYDVPY/Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.8,I.5.2},
  primaryClass = {cs}
}

@article{shenSurveyObjectClassification2019,
  title = {A Survey of {{Object Classification}} and {{Detection}} Based on {{2D}}/{{3D}} Data},
  author = {Shen, Xiaoke},
  date = {2019-05-29},
  url = {http://arxiv.org/abs/1905.12683},
  urldate = {2020-01-30},
  abstract = {Recently, by using deep neural network based algorithms, object classification, detection and semantic segmentation solutions are significantly improved. However, one challenge for 2D image-based systems is that they cannot provide accurate 3D location information. This is critical for location sensitive applications such as autonomous driving and robot navigation. On the other hand, 3D methods, such as RGB-D and RGB-LiDAR based systems, can provide solutions that significantly improve the RGB only approaches. That is why this is an interesting research area for both industry and academia.},
  archivePrefix = {arXiv},
  eprint = {1905.12683},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/BV4Y562D/Shen - 2019 - A survey of Object Classification and Detection ba.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryClass = {cs}
}

@online{StanfordCS231nConvolutional,
  title = {Stanford - {{CS231n Convolutional Neural Networks}} for {{Visual Recognition}}}
}

@article{vanhornINaturalistSpeciesClassification2018,
  title = {The {{iNaturalist Species Classification}} and {{Detection Dataset}}},
  author = {Van Horn, Grant and Mac Aodha, Oisin and Song, Yang and Cui, Yin and Sun, Chen and Shepard, Alex and Adam, Hartwig and Perona, Pietro and Belongie, Serge},
  date = {2018-04-10},
  url = {http://arxiv.org/abs/1707.06642},
  urldate = {2020-01-30},
  abstract = {Existing image classification datasets used in computer vision tend to have a uniform distribution of images across object categories. In contrast, the natural world is heavily imbalanced, as some species are more abundant and easier to photograph than others. To encourage further progress in challenging real world conditions we present the iNaturalist species classification and detection dataset, consisting of 859,000 images from over 5,000 different species of plants and animals. It features visually similar species, captured in a wide variety of situations, from all over the world. Images were collected with different camera types, have varying image quality, feature a large class imbalance, and have been verified by multiple citizen scientists. We discuss the collection of the dataset and present extensive baseline experiments using state-of-the-art computer vision classification and detection models. Results show that current nonensemble based methods achieve only 67\% top one classification accuracy, illustrating the difficulty of the dataset. Specifically, we observe poor results for classes with small numbers of training examples suggesting more attention is needed in low-shot learning.},
  archivePrefix = {arXiv},
  eprint = {1707.06642},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/H7BXI6QH/Van Horn et al. - 2018 - The iNaturalist Species Classification and Detecti.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryClass = {cs}
}

@article{wuRecentAdvancesDeep2019,
  title = {Recent {{Advances}} in {{Deep Learning}} for {{Object Detection}}},
  author = {Wu, Xiongwei and Sahoo, Doyen and Hoi, Steven C. H.},
  date = {2019-08-09},
  url = {http://arxiv.org/abs/1908.03673},
  urldate = {2020-01-30},
  abstract = {Object detection is a fundamental visual recognition problem in computer vision and has been widely studied in the past decades. Visual object detection aims to find objects of certain target classes with precise localization in a given image and assign each object instance a corresponding class label. Due to the tremendous successes of deep learning based image classification, object detection techniques using deep learning have been actively studied in recent years. In this paper, we give a comprehensive survey of recent advances in visual object detection with deep learning. By reviewing a large body of recent related work in literature, we systematically analyze the existing object detection frameworks and organize the survey into three major parts: (i) detection components, (ii) learning strategies, and (iii) applications \& benchmarks. In the survey, we cover a variety of factors affecting the detection performance in detail, such as detector architectures, feature learning, proposal generation, sampling strategies, etc. Finally, we discuss several future directions to facilitate and spur future research for visual object detection with deep learning.},
  archivePrefix = {arXiv},
  eprint = {1908.03673},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/G8D6ST5F/Wu et al. - 2019 - Recent Advances in Deep Learning for Object Detect.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Multimedia},
  langid = {english},
  primaryClass = {cs}
}

@article{zhaoObjectDetectionDeep2019a,
  title = {Object {{Detection}} with {{Deep Learning}}: {{A Review}}},
  shorttitle = {Object {{Detection}} with {{Deep Learning}}},
  author = {Zhao, Zhong-Qiu and Zheng, Peng and Xu, Shou-tao and Wu, Xindong},
  date = {2019-04-16},
  url = {http://arxiv.org/abs/1807.05511},
  urldate = {2020-01-30},
  abstract = {Due to object detection’s close relationship with video analysis and image understanding, it has attracted much research attention in recent years. Traditional object detection methods are built on handcrafted features and shallow trainable architectures. Their performance easily stagnates by constructing complex ensembles which combine multiple low-level image features with high-level context from object detectors and scene classifiers. With the rapid development in deep learning, more powerful tools, which are able to learn semantic, high-level, deeper features, are introduced to address the problems existing in traditional architectures. These models behave differently in network architecture, training strategy and optimization function, etc. In this paper, we provide a review on deep learning based object detection frameworks. Our review begins with a brief introduction on the history of deep learning and its representative tool, namely Convolutional Neural Network (CNN). Then we focus on typical generic object detection architectures along with some modifications and useful tricks to improve detection performance further. As distinct specific detection tasks exhibit different characteristics, we also briefly survey several specific tasks, including salient object detection, face detection and pedestrian detection. Experimental analyses are also provided to compare various methods and draw some meaningful conclusions. Finally, several promising directions and tasks are provided to serve as guidelines for future work in both object detection and relevant neural network based learning systems.},
  archivePrefix = {arXiv},
  eprint = {1807.05511},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/SUKCNQFT/Zhao et al. - 2019 - Object Detection with Deep Learning A Review.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  langid = {english},
  primaryClass = {cs}
}

@article{zophLearningDataAugmentation2019,
  title = {Learning {{Data Augmentation Strategies}} for {{Object Detection}}},
  author = {Zoph, Barret and Cubuk, Ekin D. and Ghiasi, Golnaz and Lin, Tsung-Yi and Shlens, Jonathon and Le, Quoc V.},
  date = {2019-06-26},
  url = {http://arxiv.org/abs/1906.11172},
  urldate = {2020-01-30},
  abstract = {Data augmentation is a critical component of training deep learning models. Although data augmentation has been shown to significantly improve image classification, its potential has not been thoroughly investigated for object detection. Given the additional cost for annotating images for object detection, data augmentation may be of even greater importance for this computer vision task. In this work, we study the impact of data augmentation on object detection. We first demonstrate that data augmentation operations borrowed from image classification may be helpful for training detection models, but the improvement is limited. Thus, we investigate how learned, specialized data augmentation policies improve generalization performance for detection models. Importantly, these augmentation policies only affect training and leave a trained model unchanged during evaluation. Experiments on the COCO dataset indicate that an optimized data augmentation policy improves detection accuracy by more than +2.3 mAP, and allow a single inference model to achieve a state-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found on COCO may be transferred unchanged to other detection datasets and models to improve predictive accuracy. For example, the best augmentation policy identified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Our results also reveal that a learned augmentation policy is superior to state-of-the-art architecture regularization methods for object detection, even when considering strong baselines. Code for training with the learned policy is available online at https://github.com/tensorflow/tpu/tree/master/models/official/detection},
  archivePrefix = {arXiv},
  eprint = {1906.11172},
  eprinttype = {arxiv},
  file = {/home/manuel/Zotero/storage/SKBPKC7R/Zoph et al. - 2019 - Learning Data Augmentation Strategies for Object D.pdf},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  langid = {english},
  primaryClass = {cs}
}


@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}