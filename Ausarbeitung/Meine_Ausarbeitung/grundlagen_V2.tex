\chapter{Grundlagen}\label{kap:grundlagen}

%####################  CHAPTER 1: Grundlagen  #################

Im folgende Kapitel wird zunächst auf die Grundlegenden Techniken
 des Machine Learings, insbesondere auf die für die Bilderkennung 
verwendeten Convolutional Neural Networks eingegangen.

Anschließend wird es um die verwendete Hardware, den Neural 
Compute Stick 2 un seine Anwendungen gehen.


%------------------- SECTION: Machine Learning ------------------

\section{Machine Learning}\label{sec:ml}

Beim Machine Lerining, welches ein Teilgebiet der Computerwissenschafen
ist, geht es um Algorithmen, die Zusammenhänge in großen Datenmengen 
erkennen sollen, ohne expliziet darauf programmiert worden zu sein.

Eine Form davon ist das \textit{Supervised Learning}, bei der das Programm 
neben den Input Daten auch die Zugehörigen Ausgaben erhällt und daraus 
dann die Regeln für Zusammenhänge herleiten soll.
Dadurch unterscheidet sich das Vorgehen wesentlich zur klassischen Programmierung,
bei bei der die Regeln vorab definiert werden.

\vspace{0.5cm}
\begin{figure}[htb]
    \centering
    \def\svgwidth{0.8\columnwidth}
    \footnotesize
    \input{Bilder/ml_classic_system.pdf_tex}
\end{figure}
\vspace{0.5cm}

Das herleiten der Regeln erfolgt beim Machine Learning dabei in einem 
iterativen Prozess, welcher als Training bezeichnet wird.
Dabei soll eine math. Funktion, welche die Zusammenhänge beschreibt 
numerisch angenähert werden. Ist der Zusammenhang linear, spricht man 
von einer Regrassion, handelt es sich um Kategorische, liegt 
ein Klassifizierung problem vor.
\\
Weitere Formen neben dem \textit{Supervised Learning} sind das 
\textit{Unsupervised Learning}, bei der das Programm keine Labels 
erhällt, sondern diese durch Clustering Verfahren selber finden 
soll, oder das \textit{Reinfocement Learning}, bei dem das Programm 
mit der Umwelt interagieren soll.
\\
Da hier jedoch ausschließlich mit dem Supervised Learing gearbeitet
wurde, werden diese Techniken nicht näher erläutert.



%------------------- SECTION: Neuronale Netze -------------------

\section{Künstliche Neuronale Netze} \label{sec:nn}


Künstliche Neuronale Netze sind eine Form des Machine Learning, 
bei der das Modell aus einer vielzal an Einheiten besteht, welche 
einen Input erhalten und dafür einen Wert ausgeben. Inspiriert 
vom menschlichen Gehirn werden diese Einheiten, auch Neuronen genannt, 
Netzwerkartig in Schichten miteinander verbunden. Dadurch können 
auch komplexere zusammenhänge zwischen In- und Output Daten 
gelernt werden.


%------------------- SUBSECTION: Das Perceptron -------------------

\subsection{Funktionsweise einzelnes Perzepreon}\label{subsec:percepron}

Die berechnung eines einzelnes Neuron ist entspricht der Logistischen 
Regression und ist in Abbildung \ref{fig:neuron} dargestellt.
\\
Zunächst werden die mit $w_{i}$ gewichteten Inputs $x_{i}$ aufsummiert 
und anschießend einer Aktivierungsfunktion $\delta(z)$ übergeben.

\begin{figure}[htb]
    \centering
    \input{Bilder/neuron}
    \caption{Einzelnes Perzeptron}
    \label{fig:neuron}
\end{figure}

Die Aktivierungsfunktion soll den Wert auf einen bestimmten Berich skallieren.
Für einen binären klassifikator, also $y = 1$ oder $0$ wird dafür die 
\textit{Simoid Funktion} verwendet, welche einen Wert S-Förmig ziwschen 0 ind 1 
skalliert. 

Die vorhersage berechnet sich demnach aus 

\begin{align}
    \label{eq:neuron}
    z = \sum_{i}(w_{i}x_{i} + b)\\
    y = \frac{1}{1 + e^{-z}}
\end{align}
%hier plot

Mithilfe einer Loss Funktion $L(y,w)$ wird nun bestimmt wie sehr sich geschätze 
Wert $y$ von dem tatsächlichen Wert $\hat{y}$ unterscheidet.

Für Regressions Probleme wird dafür oft der Absolute oder Quadratische Abstand
verwendet. Bei Klassifikationen ist jedoch eine Logarithmische Fehler berechnung 
effektiver.

Durch den Logarithmus wird der Loss um so größer, je weiter die Schätzung $y$ (0 bis 1) vom 
tatsächlichen Wert $\hat{y}$ (0 oder 1) abweicht. 

\begin{equation}
    \label{eq:crossentropy}
    L = \hat{y}log(y) + (1 - \hat{y})log(1 - y)
\end{equation}
%hier plot


Um nun die Schätzungen $\hat{y}$ beim nächsten mal zu verbessern muss die 
Lossfunktionen minimiert werden. Dafür wird das Gradienten Verfaheren angewandt 
bei dem die Loss funktion partiell nach den Parametern $W_{i}$ und $b_{i}$ 
abgeleitet wird.

\begin{equation}
    \label{eq:grad}
    \frac{\partial L}{\partial w} = \frac{\partial L}{\partial z}\frac{\partial z}{\partial w}
\end{equation}

Nun können die Parameter $W$ und b angepasst werden.

\begin{equation}
    \label{eq:update_wieghts}
    w  \leftarrow w - \eta \frac{\partial L}{\partial w}
\end{equation}

wobei die \textit{Leariningrate} $\eta$ die Schrittweite mit der die Anpassung vorgenommen
werden soll angibt.

Die Sritte (\ref{eq:neuron}) bis (\ref{eq:update_wieghts}) werden dann solange wiederholt, 
bis der Loss genügend minimiert wurde.
\\
Dabei können entweder alle Input Daten auf einmal \textit{Batch 
gradient Descent}, nur ein Teil \textit{Mini Batch} oder nur 
ein zufallig ausgewähltes \textit{Stochastic Gradient 
Descent} verwendet werden.


%------------------- SUBSECTION: MLP -------------------
\subsection{Mehrschichtiges Netz}\label{subsec:mlp}

Da die möglichkeiten mit einem einzelnen Neuron stark bergrenzt sind 
werden für komplexere Zusammenhänge mehrere Neuronen in Schichten 
miteinander Verbunden. Die Verbindungen sind unterschiedlich stark 
gewichtet wodurch auf Eingaben in die erste Schicht \textit{Input Layer} 
an der Letzten Schicht,\textit{Output Layer} die zugehörigen Ausgaben 
erzeugt werden können. 

\begin{figure}[htb]
    \centering
    \input{Bilder/neuralnetwork.tex}
    \caption{Neural Network Struktur}
    \label{fig:nn}
\end{figure}



Die berechnung erfolgt gleich wie beim einzelnen Perzepron für alle Neuronen 
einer Schicht glleichzeitig mit matrixmultiplitkation

\begin{equation}
    \label{mat:feedforward}
    \begin{pmatrix}
        x_{0} & x_{1} & x_{2}
    \end{pmatrix}
    \cdot
    \begin{pmatrix}
        w_{0,1} & x_{0,2}\\
        w_{1,1} & x_{1,2}\\
        w_{2,1} & x_{2,2}\\
    \end{pmatrix}
    =
    \begin{pmatrix}
        y_{1}\\
        y_{2}
    \end{pmatrix}
\end{equation}


Die Ergebnisse der Aktivierungsfunktion in einer Schicht dienen 
dann als Input für die nächste Schicht. Für \textit{Hidden Layer}
wird anstelle der in \ref{subsec:percepron} beschrieben Sigmoid 
Funktion ReLu verwendet, da das skallieren zw 0 und 1 nur für die 
Ausgabe Schicht

\begin{equation}
    \label{eq:relu}
    \delta(z) = max(0,z)
\end{equation}

Diese setzt nur die negativen Werte zu 0. Durch die dadurch erhaltenen
größeren Gradienten kann das Netzt Schneller lernen.


Enthält die Output Schicht mehr als ein Neuron, soll also keine binäre sondern 
Kategorische Klassifizierung erreicht werden, wird anstelle der Sigmoid 
die \textit{Softmax} Funtion verwendet.


\begin{equation}
    \label{eq:softmax}
    \delta(z) = \frac{e^{z}}{\sum e^{x}}
\end{equation}

welche eine Wahrscheinlichkeitsverteilung über allen Output 
Neuronen bildet, die sich zu 1 aufsummeiren lässt. Somit ergebt sich
für jedes Output Neuron, das für eine mögliche Klasse steht, eine 
wahrscheinlichkkeit, mit der es sich um diese klasse handelt.
\\
Um nun für die berechnete Lossfunktion die Anpassungen für die 
einzelnen Gewichte zu berehnen, werden Schrittweise die Partiellen
Ableitungen rückwarts für alle Layer vorgenommen, \textit{Backpropaetion}
sodass für die Layer $L = 1...N$ die Gradienten $\frac{\partial L}{\partial 
w_{1}}$ bis $\frac{\partial L}{\partial w_{L}}$ zur Anpassung 
der w Matrizen entsteht.
\\
Neben dem Ansatz des Gradienten Descent für die Optimierungs 
gibt es noch weitere, effizientere verfahren wie z.B. Momentum oder Adam.



%------------------- SUBSECTION: Validierung -------------------
\subsection{Validierung und Overfitting}

Um zu erkennen, ob das Netz die Trainings Daten nur 'auswendig' lernt, oder die 
Zusammenhänge in ihnen für neue Daten generalisiert hat, wird während des Trainings 
eine Validierung durchgeführt. Dafür wird das Datenset in ein Trainings- und in 
ein Test Set aufgeteilt und nur mit den Trainingsdaten die Backpropagation zur 
Parameter Anpassung durchgeführt. Mit dem Test Datensatz wird nur der Loss berechnet und
mit ausgegeben. Wenn sich nur der Trainings Loss veingert \ref{fig:loss_plot} ist das ein zeichen 
für Overfitting, das heist keine generalisierung findet statt. 


\begin{figure}[htb]
    \centering
    \input{Bilder/plot.tex}
    \caption{irgend ein plot}
    \label{fig:ptl}
\end{figure}

Grund dafür sind entweder zu wenige Trainingsdaten oder das Netz hat zu viele Neuronen, ist also 
überparametrisiert, und damit zu viele Freiheiten sich den Daten anzupassen. \ref{fig:overfit} 
\\
Hat das Modell zu wenige Parameter um die komplexität der Daten anzugleichen, Bsp, Gerade an Funktion 
höreren Grades, spricht man von Underfitting. \ref{fig:underfit}

% hier plots von linie durch datenpunkte


% Overfitting -> hohe varianz: varianz = train_err - test_error
% Underfitting -> hoher Bias: Bias = 


Um Overfitting zu vermeiden können entweder mehr Trainingsdaten verwendet werden. Stehen diese 
jedoch nicht zu verfügung, kann Regularisierung verwendet werden, eine Technik die neben der 
minimierung der Loss Funktion auch versucht die Gewichte auf einem kleinen Wert zu halten. 
Dafür wird der zu minimierenden Loss Function als weiterer 
Therm eine aufsummierung aller quadrieten Gewichte hinzugefügt. (\ref{eq:regularization}) 
\cite{geronHandsonMachineLearning2017}


\begin{equation}
    \label{eq:regularization}
    J(w) = E + \lambda \sum_{i} w_{i}^{2}
\end{equation}

% Early Stopping
Weitere Möglichkeiten sind Daten Augemntierung oder Drop Out, auf die 
in Abschnitt \ref{sec:deepl_cv} genauer eingegangen wird.



%------------------- SECTION: DEEP LEARNIN UNG COMPUTER VISION ----------------
\section{Deep Learning und Computer Vision}\label{sec:deepl_cv}

Neben den in \ref{sec:nn} beschrieben sogenannten \textit{Feed Forward Netzen} 
gibt es eine vielzahl an Erweiterungen der Netzwerk Architektur, für unterschiedliche 
Anwendugsgebiete, die jedoch alle das beschriebene Grundprinzip verwenden.\\

Hat ein NN mehr als eine Hidden Schicht, spricht man von Deep Lerining.

Arten von NNs:
\begin{itemize}
    \item CNN: für bilder, durch faltung erkennt features und ist translatorisch invariant: \textbf{Image Classification}
    \item Recurrecnt Neural Networks/LSTM: durch feedback in network: für Audio und zeitl. anwendungen 
    \item Autoencoder, GANs, etc.
\end{itemize}

Computer Vision beschäftigt sich mit der Bild erkennung und Objekt Lokalisierung. 
Anwendungen sind gesichtserkennung oder Autonomes Fahren. 



%------------------- SUBSECTION: CNNs -------------------
\subsection{Convolutional Neural Networks}

Um Bilder /Inhalte mithilfe Neuronaler Netze zu erkennen, 
werden die einzelnen Pixelwerte der Bilder als Inputs verwendet 
und das auf dem Bild zu erkennende Objekt als output verwendet. Bilder 
werden als Matrizen der Form $height\times width \times color channels$ 
dargestellt.

Da dies für regulere/vollständig verbundene Neuronale Netze eine 
enorme Anzahl an Parametern und damit einhergenhender rechenkost 
bedeuten würde, werden hier CNNs verwendet, eine Architektur in 
der Paramer von verschiedenen Neuronen gemeinsam genutzt werden.

Hauptbestandteil von CNNs sind die \textit{Convolutional Layers}
welche die mathematische Faltungsoperation zwischen Input Bild 
und Filter/Kernel durchführen.

Die Filter meist der Form $3 \times 3$ oder $5 \times 5$ und mit der 
selben Tiefe wie der Input, werden während des \textit{Forward 
Pass/bropagation} zeilenweise über das Bild geschoben und an jeder Stelle 
das Kreuzprodukt berechnet. Jedes Ergebnis dieser berechnungen ergibt einen
Pixel Wert der nächsten Schicht auch Feature Map genannt. \ref{fig:cnn}

Ein weiterer bestandteil von CNNs sind die Pooling Layer, welche eine 
bestimmte Anzahl an Pixeln zB 3 x 3 zu einem Wert zusammenfassen wodurch 
sich die Parameter Anzahl des Bildes veringert. Das hat den Vorteil, dass 


\begin{figure}[htb]
    \centering
    \label{fig:lenet}
    \includegraphics[width=0.8\textwidth]{Bilder/lenet.png}
    \caption{LeNet-5 cite lecun}
\end{figure}



Ziel dieser Operation ist es, dass die 
Filter Maps bestimmte Muster/features die zu einer bestimmten klasse 
gehren lernen. Mit diesen Filtern können dann unabhängig wo im Bild 
befindlich, die features wie zb horizontale/vertikale linien, Ecken 
oder Kreise gefunden werden. 
\\
Beispiel:
\begin{equation}
    \begin{pmatrix}
        1 & 0 & -1\\
        1 & 0 & -1\\
        1 & 0 & -1
    \end{pmatrix}
\end{equation}

erkennt vertikale Linien im Bild. 




Conv layer:\\
Faltung an cnn erklärt: input image als (h,w,c) tensor wird mit filter/kernel gefaltet. daraus erhält man feature map
zusammen mit pool layer:\\
pool layer erklärt\\

ergibt grundstruktur von cnn\\

weitere layer wie dropout\\

%------------------- SUBSECTION: Transfer Learining ----------------
\subsection{Transfer Learining}

erklären, dass features von einfach bis immer komplexer werdende muster enthalten, die im bild zu finden sind.
\\
filter können zufällig initialisiert und gelernt werden, oder von vortrainierten netzen wieder verwendet
werden. (transfer learining oder fine tuning) da die deatures (besonders in den vorderen layern) immer ähnlich sind und das
neu lernen zeitaufwändig und oft sogar ungenauer ist.
\\
je nach ähnlichkeit des eig datensetz zu dem auf das netz urspr trainiert wurde:\\
scratch, fine tuning, feature extractor


%------------------- SUBSECTION: Competitions ----------------
\subsection{Competitions mit Imagenet und co + cnn winner}\label{subsec:comp}

zuerst competition erklären \\
dann chronologische gewinner netzt + besonderheit\\




%------------------- SUBSECTION: Object Detection ----------------
\subsection{Objekt erkennung}\label{sec:objdet}


Unterschied deutlich machen: klassifikator kann nur ges bild auswertuen und wahscheinlichk angeben welche 
klasse darauf. keine lokalisierng und keine mult obj\\

3 Arten der Bilderkennung: Klassifizierung, Objekt Erkennung (für mult + box), Segmentation (jeden pixel)

dafür obj erkennung notw:\\

Single Shot Detectoren
\\

Two Stage Detectoren


% hier irgendwo die frameworks einbringen
\subsection{Machine Learning Frameworks}

Die Algorithmen müssen nicht jedesmal neu implementiert werden. 
Für die gängigen verfahren gibt es Frameworks, welche 
die Implementierung enthalten und über APIs verwendet 
werden können (Bsp Tensorflo und Keras)


%------------------- SECTION: Hardware ----------------------

\section{Hardware}\label{sec:hardware}
%noch eine section zu Hardware allg (cpu, gpu, tpu), Neural Compute Stick und AI on the egde


allg zu hardware für deeplearning. Das besser auf gpu als cpu. weitere: tpu, fpga, vpu, wie zb ncs2.

\subsection{Neural Compute Stick 2}

technischen spezifikationen




%------------------- SUBSECTION: AI on the Edge ----------------

\subsection{AI on the edge}

was bedeutet dies. cloud unabhängig und ohne groß rechner. bsp anwendungen.

