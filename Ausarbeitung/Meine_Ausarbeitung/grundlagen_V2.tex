\chapter{Grundlagen}\label{kap:grundlagen}

%####################  CHAPTER 1: Grundlagen  #################

Im folgende Kapitel wird zunächst auf die Grundlegenden Techniken
 des Machine Learings, insbesondere auf die für die Bilderkennung 
verwendeten Convolutional Neural Networks eingegangen.

Anschließend wird es um die verwendete Hardware, den Neural 
Compute Stick 2 un seine Anwendungen gehen.


%------------------- SECTION: Machine Learning ------------------

\section{Machine Learning}\label{sec:ml}

Beim Machine Lerining, welches ein Teilgebiet der Computerwissenschafen
ist, geht es um Algorithmen, die Zusammenhänge in großen Datenmengen 
erkennen sollen, ohne expliziet darauf programmiert worden zu sein.

Eine Form davon ist das \textit{Supervised Learning}, bei der das Programm 
neben den Input Daten auch die Zugehörigen Ausgaben erhällt und daraus 
dann die Regeln für Zusammenhänge herleiten soll.
Dadurch unterscheidet sich das Vorgehen wesentlich zur klassischen Programmierung,
bei bei der die Regeln vorab definiert werden.

\vspace{0.5cm}
\begin{figure}[htb]
    \centering
    \def\svgwidth{0.8\columnwidth}
    \footnotesize
    \input{Bilder/ml_classic_system.pdf_tex}
\end{figure}
\vspace{0.5cm}

Das herleiten der Regeln erfolgt beim Machine Learning dabei in einem 
iterativen Prozess, welcher als Training bezeichnet wird.
Dabei soll eine math. Funktion, welche die Zusammenhänge beschreibt 
numerisch angenähert werden. Ist der Zusammenhang linear, spricht man 
von einer Regrassion, handelt es sich um Kategorische, liegt 
ein Klassifizierung problem vor.
\\
Weitere Formen neben dem \textit{Supervised Learning} sind das 
\textit{Unsupervised Learning}, bei der das Programm keine Labels 
erhällt, sondern diese durch Clustering Verfahren selber finden 
soll, oder das \textit{Reinfocement Learning}, bei dem das Programm 
mit der Umwelt interagieren soll.
\\
Da hier jedoch ausschließlich mit dem Supervised Learing gearbeitet
wurde, werden diese Techniken nicht näher erläutert.


%------------------- SECTION: Neuronale Netze -------------------

\subsection{Künstliche Neuronale Netze} \label{sec:nn}

Für komplexe Input Daten, wie beispielsweise Bilder, bei denen 
die einzelnen Pixelwerte als Inputs und der Inhalt des Bildes als 
Output dienen, werden in der Regel künstliche Neuronale Netze verwendet.
Diese sind eine Form des Machine Learings und bestehen aus einer 
vielzahl an miteinander verbundener Neuronen. Durch unterschiedlich 
starke Gewichtungen der einzelnen Verbindungen, auch Gewichte genannt, 
können für unterschiedliche Input Daten die entsprechenden Outputs 
gefunden werden.

\begin{figure}[htb]
    \centering
    \label{fig:nn}
    \def\svgwidth{0.5\columnwidth}
    \footnotesize
    \input{Bilder/nn.pdf_tex}
\end{figure}


Die richtige einstellung der Gewichte, welche zunächst zufällig initialisiert werden, 
erfolgt dabei im Trainingsprozess, welcher in \ref{fig:train} schematisch
 dargestellt ist und sich in die drei Schritte:
\begin{itemize}
    \item Feed Forward anhand aktueller Gewichte vorhersage aus den Inputs treffen
    \item Lossfuction Abweichung zu tatsächlichen werten bestimmen
    \item Backpropagation minimierung der Fhlerfunktion durch anpassung der Gewichte
\end{itemize}

\begin{figure}[htb]
    \centering
    \label{fig:train}
    \def\svgwidth{0.5\columnwidth}
    \input{Bilder/train_workflow.pdf_tex}
    \caption{Trainingsablauf NN}
\end{figure}

Durch häufiges wiederholen dieser Schritte kann die Fehlerfunktion soweit minimiert werde, 
dass das Modell auch für neue Input Daten die richtigen Aussagen treffen kann.


%------------------- SUBSECTION: Das Perceptron -------------------

\subsubsection{Vorwärts}\label{subsec:percepron}

Im Vorwärtsdurchgang wird der Input durch alle Schichten hindurch 
gereicht, um in der letzten Schicht den gewünschten Output zu liefern.
Dabei erhält jedes Neuron wie in \ref{fig:neuron} dargestellt, die Ausgaben aller
 neuronen der vorherigen Schicht, summiert diese auf und übergibt den Wert
  einer Aktivierungsfunktion, die den Wert auf einen bestimmten Bereich Skalliert.
 

\begin{figure}[htb]
    \centering
    \input{Bilder/neuron}
    \caption{Einzelnes Perzeptron}
    \label{fig:neuron}
\end{figure}

Die Berechnung des Vorwärtsdurchgangs von einer ges Schicht 
zur nächsten, lässt sich die mithilfe der Matrixixmultiplikation
durchführen, was Gl. in ... als Vektorschreibweise ergibt.
\\
y = a(WTX)\\
wobei a() die Aktivierungsfunktion.
\\
Aktivierungsfunktion können sein
\begin{equation}
    \label{eq:relu}
    \delta(z) = max(0,z)
\end{equation}
ReLU in den hidden Layer
oder

\begin{equation}
    \label{eq:softmax}
    \delta(z) = \frac{e^{z}}{\sum e^{x}}
\end{equation}

\begin{equation}
    \label{eq:sidmoid}
    \delta(z) = \frac{1}{1 + e^{-x}}
\end{equation}


sigmoid(bin) oder softmax(cat) im letzten layer

bei softmax erhällt man Wahrscheinlichkeitsverteilung über allen Output
neuronen.\\
Neben dem Ansatz des Gradienten für die Optimierungs 
gibt es noch weitere, effizientere verfahren wie z.B. Momentum oder Adam.


\subsubsection{Fehlerfunktion}

Die Abweichung der Schätzung, welche an den Neuronen der letzen Schicht 
vorliegen, zu den tatsächlichen Werten, den Labels, wird mithilfe geeigneter 
Fehlerfunktion bestimmt. Für Ragression z.B. abs oder rms und für Kategorisch
häufig logarithmisch.

hier am beispiel einer binären klassifikation (erg 0 oder 1) mit log loss
 (crossentropy) dargestellt.

 \begin{equation}
    \label{eq:crossentropy}
    L = \hat{y}log(y) + (1 - \hat{y})log(1 - y)
\end{equation}

Durch den Logarithmus wird der Loss um so größer, je weiter die Schätzung $y$ vom 
tatsächlichen Wert $\hat{y}$ abweicht.
%hier plot
\subsubsection{Backpropagation}
Durch berechnung des Gradienten der Fehlerfunktion kann ermittelt 
werden in welche Richtung die Gewichte angepasst werden müssen, sodass sie sich 
im nächsten Durchgang minimiert.
Dafür wird die die Fehlerfunktion für jede Schicht partiell nach den 
Gewichten abgeleitet, was wie in gl. \ref{eq:grad} dargestellt mithilfe der 
Kettenregel für die Aktivierungsfunktion geschieht.


\begin{equation}
    \label{eq:grad}
    \frac{\partial L}{\partial w} = \frac{\partial L}{\partial z}\frac{\partial z}{\partial w}
\end{equation}
Damit werden die Gewichte dann nach Gleichung \ref{eq:update_wieghts} angepasst.
\begin{equation}
    \label{eq:update_wieghts}
    w  \leftarrow w - \eta \frac{\partial L}{\partial w}
\end{equation}

wobei die \textit{Leariningrate} $\eta$ die Schrittweite mit der die Anpassung vorgenommen
werden soll angibt.








%------------------- SUBSECTION: Validierung -------------------
\subsection{Validierung und Overfitting}

um überprüfen zu können ob ein Modell die Trainingsdaten tatsächlich generalisiert 
hat, dh auch für neue daten anwendbar ist, oder diese nur auswendig gelernt hat, 
wird häufig der Datensatz in einen Trainingsanteil und einen Testanteil aufgeteilt.

Mit dem Testdatensatz wird dann schon wärend des Trainings regelmäßig zwischen geprüft, 
veringert sich irgendwann nur noch der fehler der trainingsdaten, findet overfitting statt.

% \begin{figure}[htb]
%     \centering
%     \input{Bilder/plot.tex}
%     \caption{irgend ein plot}
%     \label{fig:ptl}
% \end{figure}

Häufig sind zu wenige Trainingsdaten oder zu komplexe/überparametrisierte
 Modelle und damit zuviele freiheitsgrade, grund für overfitting.

% hier plots von linie durch datenpunkte

% Overfitting -> hohe varianz: varianz = train_err - test_error
% Underfitting -> hoher Bias: Bias = 

Techniken um Overfitting zu vermeiden sind z.B.
\begin{itemize}
    \item Augmentierung der Daten
    \item Regularisierung der Parameter (L1/L2)
    \item Dropout
    \item early stopping
\end{itemize}

Bei Augmentierung werden aus den vorhandenen Daten künstlich mehr 
Daten generiert, in dem an den Bildern geometrische transformationen 
oder manipulationen der pixelwerte vorgenommen werden.
\\
Bei Regularisierung wird an die Lossfuction als weiterer Term
 eine aufsummierung der Gewichte gehängt, wodurch diese bei der Minimierung 
  klein gehalten werden, wodurch weniger potential zur überanpassung da ist.
  \begin{equation}
    \label{eq:regularization}
    J(w) = E + \lambda \sum_{i} w_{i}^{2}
\end{equation}

Beim Dropout werden zufällig gewichte zu 0 gesetzt.
\\
early stopping: stoppen des trainings, wenn sich overfitting einstellt.




%------------------- SECTION: DEEP LEARNIN UNG COMPUTER VISION ----------------
\subsection{Convolutional Neural Networks}\label{sec:cnn}

Für die Bilderkennung werden typischerweise Convolutionael 
Neural Networks (CNNs) verwendet. Hierbei handelt es sich um eine Erweiterung
der in \ref{sec:nn} beschriebenen Neuronalen Netze. Beim CNN 
sollen vor der Klassifikation, Merkemale des Input Bildes,
die spezifisch für eine Klasse sind herausextrahiert werden.

Dafür werden über das Bild zeilenweise Filtermatrizen mit kleinerer Dimension
(3x3, 5x5) geschoben und eine math Faltung angewendet.
Die Ergebnisse der Faltungen ergeben eine sog Feature Map, in welcher 
Muster die sowol in Filter Mtrix als auch in input Bild auftreten, verstärkt 
dargestellt werden.

Die Werte der Filter Matrizen entsprechen den zu lernenden Gewichten 
und werden mithilfe der Backpropagation angepasst.

\begin{figure}[htb]
    \centering
    \label{fig:conv}
    \includegraphics[width=0.4\columnwidth]{convolution.png}
    \caption{Faltung, \cite{researcherSimpleIntroductionConvolutional2019}}
\end{figure}



Durch die hintereinanderschaltung mehrerer Convolutional Layern 
lassen sich so immer komplexere Merkmale des Input Bildes in den 
Feature Maps heraus extrahieren.

Durch Subsampling Methoden wie Max Pool Layer zwischen den Convolutional
Layern verkleinert sich die Dimension der Ferture Maps in jeder Schicht.


\begin{figure}[htb]
    \centering
    \label{fig:conv}
    \includegraphics[width=0.8\columnwidth]{lenet.png}
    \caption{Faltung, \cite{lecunGradientBasedLearningApplied1998}}
\end{figure}


Vorteile der CNNs sind der geringere Rechenaufwand durch die gemeinsame 
Nutzung der Paramer der Filter Matrizen und die durch die 
Faltung zustande kommende räumliche invarianz für das zu erkennende 
Objekt auf dem Bild.
\\
Um die Features, welche insbesondere in den vordersten ConvLayern für 
alle klassen sehr ähnlich sind, nicht bei jedem Modell von grund auf 
neu lernen zu müssen, wird häufig \textit{Transfer Learing} angewendet, 
d.h. es werden die auf ein allg Datenset wie z.B. ImageNet vortrainierten
Gewichte verwendet und müssen so nur noch leicht für den eigenen Datensatz 
fine getuned werden.


\subsubsection{Architkturen}
historie, bzw gewinner Modelle der ImageNet Challenges

\begin{itemize}
    \item Lente5
    \item Alexnet
    \item Inception
    \item Resnet
\end{itemize}


%------------------- SUBSECTION: Object Detection ----------------
\subsubsection{Objekt erkennung}\label{sec:objdet}

Neben der Information, was sich auf einem Bild befindet möchte
man bei der Object Detection auch herausfinden wo sich das 
Objekt befindet.




%------------------- SECTION: Hardware ----------------------

\section{Hardware}\label{sec:hardware}
%noch eine section zu Hardware allg (cpu, gpu, tpu), Neural Compute Stick und AI on the egde


allg zu hardware für deeplearning. Das besser auf gpu als cpu. weitere: tpu, fpga, vpu, wie zb ncs2.

\subsection{Neural Compute Stick 2}

technischen spezifikationen




%------------------- SUBSECTION: AI on the Edge ----------------

\subsection{AI on the edge}

was bedeutet dies. cloud unabhängig und ohne groß rechner. bsp anwendungen.

