\chapter{Realisierung Objekt Erkennung}\label{kap:object_det}

\section{Datensatz}\label{sec:dataset}

Um ein Deep Learning Modell richtig trainieren zu können, 
wird eine große Menge an gelabelten Trainingsdaten benötigt.
Im Falle der Objekterkennung enthalten die labels neben der 
Klasse auch die Koordinaten der Bounding Boxen, 
welche das zu erkennende Objekt auf dem Bild umrahmen.


Für die vorliegende Arbeit wurden dafür aus dem Open Source 
Dataset \textit{OpenImages} \cite{kuznetsovaOpenImagesDataset2018} 
von Google 9 Klassen, welche Wildtiere enthalten heruntergeladen.

Dieses besteht aus einem Trainingsset mit 200 bis 2000 Bildern pro 
Klasse sowie kleineren Test- und Validierungssets. Um für alle Klassen 
die gleiche Anzahl an Trainingsdaten zu erhalten und um Overfitting zu 
verhindern wurden wie im folgenden beschrieben die Trainingsdaten 
augmentiert.

\subsection{Augmentierung}

Augmentierung ist eine Technik, mit der aus den vorhandenen 
Daten künstlich mehr Daten generiert werden können. Dafür werden 
z.B. geometrische Transormationen, wie etwa Sklierung, Verschiebung 
Rotieren und Spiegelungen oder manipulationen der Pixelwerte 
zur veränderung der Farbwerte, Helligkeit, Kontrast oder 
Rauschen vorgenommen.

Mithilfe eines Python Scripts und der Library \textit{imgaug} \cite{imgaug}
konnten so verschiedene Augmentierungstechniken auf das Datenset angewendet
werden.

\begin{figure}[H]
    \centering
    \label{fig:augmentierung}
    \includegraphics[width=0.8\columnwidth]{Bilder/augmentierung.png}
    \caption{Anwendung von Augmentierungstechniken}
\end{figure}


\section{Training}

Da der Neural Compute Stick mit OpenVino ein eigenes Datei Format 
für die traininerten Modelle verwendet, musste bei der Auswahl
eines Frameworks sowie Models auf die Kompatibilität zu OpenVino 
geachtet werden. 

% Verwendete wurde daher das untersstütze Framework Tensorflow, 
% um zwei Ansätze zu verfolgen. Der eine verwendet die Api Keras, 
% und versucht neben der Klassifikation die Lokalisierung mit 
% dieser vorzunahemen, der andere verwendet eine speziell für die 
% Objekterkennung konzipierte Api für wie in Abschnitt
%  \ref{sec:related_work} beschriebene End-to-End lösungen.


\subsection{Tensorflow Object Detection Api}

Die Tensorflow Object Detection Api ist unter den Research Modellen
\cite{tfobjdet} des offiziellen Tensorflow Repository zu
finden und enthällt implementierungen einiger gängiger Object Detectin
Modelle, wie Single Shot Detectors (SSD) und Faster R-CNNs mit 
verschiedenen Basis CNNs mit vortrainierten Geweichten.

Um die Modelle trainieren zu können, mussten zunächst die 
Trainingsdaten in das binary Dateiformate TFRecords umgewandelt 
werden, welches die Api verwendet. Dieses ist eine Serialisierte 
darstellung der Bilder und Labels als Protocol Buffer für
effizienten Zugriff auf diese.

Trainiert wurde mit hilfe \textit{Google Colab}, eine cloudbasierte VM,
welche eine geeignete Gpu zur verfügung stellt.


\subsection{Trainingsworkflow}

Das Ergebnis des Trainings kann neben der Auswahl eines geeigneten 
Modell, sowie auswahl und aufbereitung des Datensatzes auch durch 
anpassungen sogenannter Hyperparameter beeinflusst werden.

Mit diesen können in \ref{subsec:validation} beschriebene 
Verfahren realisiert werden.

Durch eine Evaluierung zur Laufzeit des Trainings können so Fehler 
in der Konfigureation des Trainings erkannt und durch anpassen von 
entweder Datensatz, Modell oder Parameter korrigiert/verbessert 
werden.
Es ergibt sich folgender Workflow.

\begin{figure}[H]
    \centering
    \def\svgwidth{0.7\textwidth}
    \input{Bilder/train_workflow_gesammt.pdf_tex}
    \caption{Trainingsworkflow}
    \label{fig:train_workflow}
\end{figure}

Die Ergebnisse werden im nächsten Kapitel (\ref{kap:eval}) diskutiert.
