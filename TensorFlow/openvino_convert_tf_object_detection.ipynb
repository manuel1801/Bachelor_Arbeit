{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert TF Object Detection Models for Open Vino Inference Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T03:16:37.671883Z",
     "start_time": "2019-02-20T03:16:37.658920Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "workspace_dir = '/home/manuel/Bachelor_Arbeit/TensorFlow/workspace'\n",
    "dataset = 'OI_Animals_9'\n",
    "model = 'faster_rcnn_resnet50_coco_2018_01_28_out'\n",
    "\n",
    "checkpoint = 199666\n",
    "model_type_json = 'faster_api'\n",
    "pipeline_config_file = 'faster_res50'\n",
    "img_size = 600\n",
    "channel = 3\n",
    "batch_size = 1\n",
    "\n",
    "model_type = {\n",
    "    'faster': '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/faster_rcnn_support.json',\n",
    "    'faster_api': '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/faster_rcnn_support_api_v1.14.json',\n",
    "    'ssd' : '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_support.json',\n",
    "    'ssd_api' : '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_support_api_v1.14.json',\n",
    "    'rfcn' : '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/rfcn_support.json',\n",
    "    'rfcn_api' : '/opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/rfcn_support_api_v1.14.json'\n",
    "}\n",
    "\n",
    "config_file = {\n",
    "    'ssd_mob': 'ssd_mobilenet_v2_coco.config', \n",
    "    'ssd_mob_oi': 'ssd_mobilenet_v2_oid_v4.config', \n",
    "    'ssd_inc':  'ssd_inception_v2_coco.config',\n",
    "    'faster_inc': 'faster_rcnn_inception_v2_coco.config',\n",
    "    'rfcn_res101':  'rfcn_resnet101_pets.config',\n",
    "    'faster_res50': 'faster_rcnn_resnet50_coco.config'\n",
    "}\n",
    "\n",
    "pb_file = os.path.join(workspace_dir, dataset, model, 'exported', 'frozen_inference_graph.pb')\n",
    "\n",
    "configuration_file = model_type[model_type_json]\n",
    "\n",
    "pipeline = os.path.join(workspace_dir, dataset, model, config_file[pipeline_config_file])\n",
    "\n",
    "plugin_device = 'MYRIAD'\n",
    "\n",
    "data_type = 'FP16'\n",
    "\n",
    "input_shape_str = '['+ str(batch_size) +',' + str(img_size) + ',' + str(img_size) + ',' + str(channel) + ']'\n",
    "\n",
    "output_dir = os.path.join(workspace_dir, dataset, model, 'open_vino')\n",
    "\n",
    "mo_tf_path = '/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py'\n",
    "input_shape_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_str = os.path.join(workspace_dir, dataset, model, 'model.ckpt-' + str(checkpoint))\n",
    "exported = os.path.join(workspace_dir, dataset, model, 'exported')\n",
    "\n",
    "!python3 /home/manuel/Bachelor_Arbeit/TensorFlow_Models/object_detection/export_inference_graph.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --pipeline_config_path $pipeline \\\n",
    "    --trained_checkpoint_prefix $checkpoint_str \\\n",
    "    --output_directory $exported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  convert for open vino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python3 {mo_tf_path} \\\n",
    "--input_model {pb_file} \\\n",
    "--tensorflow_use_custom_operations_config {configuration_file} \\\n",
    "--input_shape {input_shape_str} \\\n",
    "--data_type {data_type} \\\n",
    "--input image_tensor \\\n",
    "--tensorflow_object_detection_api_pipeline_config {pipeline} \\\n",
    "--output_dir {output_dir}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openvino.inference_engine import IENetwork, IEPlugin, IECore\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_dir = '/home/manuel/Bachelor_Arbeit/workspace'\n",
    "dataset = 'OI_Animals_Augmented_9_2000'\n",
    "model = 'ssd_inception_v2_coco_2018_01_28_out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xml = os.path.join(workspace_dir, dataset, model, 'open_vino', 'frozen_inference_graph.xml')\n",
    "model_bin = os.path.join(workspace_dir, dataset, model, 'open_vino', 'frozen_inference_graph.bin')\n",
    "\n",
    "labels = [l.strip() for l in open(os.path.join(workspace_dir, dataset, 'classes.txt')).readlines()]\n",
    "\n",
    "test_images_dir = os.path.join(workspace_dir, dataset, 'validation')\n",
    "\n",
    "assert os.path.isfile(model_bin)\n",
    "assert os.path.isfile(model_xml)\n",
    "assert os.path.isdir(test_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect images\n",
    "if os.path.isdir(test_images_dir):\n",
    "    images = [\n",
    "        os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img[-3:] == 'jpg']\n",
    "    print(str(len(images)) + ' images found')\n",
    "    shuffle(images)\n",
    "elif os.path.isfile(test_images_dir) and test_images_dir[-3:] == 'jpg':\n",
    "    print('one image found')\n",
    "    images = [test_images_dir]\n",
    "else:\n",
    "    print('wrong input')\n",
    "    exit()\n",
    "    \n",
    "frame = cv2.imread(images[0])\n",
    "initial_h, initial_w = frame.shape[: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the infer net\n",
    "ie = IECore()\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "\n",
    "exec_net = ie.load_network(network=net, num_requests=2, device_name='MYRIAD')\n",
    "\n",
    "img_info_input_blob = None\n",
    "feed_dict = {}\n",
    "for blob_name in net.inputs:\n",
    "    if len(net.inputs[blob_name].shape) == 4:\n",
    "        input_blob = blob_name\n",
    "    elif len(net.inputs[blob_name].shape) == 2:\n",
    "        img_info_input_blob = blob_name\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported {}D input layer '{}'. Only 2D and 4D input layers are supported\"\n",
    "                               .format(len(net.inputs[blob_name].shape), blob_name))\n",
    "\n",
    "assert len(net.outputs) == 1, \"Demo supports only single output topologies\"\n",
    "\n",
    "out_blob = next(iter(net.outputs))\n",
    "n, c, h, w = net.inputs[input_blob].shape\n",
    "if img_info_input_blob:\n",
    "    feed_dict[img_info_input_blob] = [h, w, 1]\n",
    "\n",
    "cur_request_id = 0\n",
    "next_request_id = 1\n",
    "\n",
    "frame = cv2.imread(images[0])\n",
    "initial_h, initial_w = frame.shape[: 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
