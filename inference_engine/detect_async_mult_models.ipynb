{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/manuel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from openvino.inference_engine import IENetwork, IEPlugin, IECore\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to Dataset Dir\n",
    "workspace_dir = '/home/manuel/Bachelor_Arbeit/workspace'\n",
    "labels = []\n",
    "\n",
    "# 1. Dataset and Model\n",
    "dataset = 'OI_Animals_Augmented_9_2000/'\n",
    "model = 'faster_rcnn_inception_v2_coco_2018_01_28_out/'\n",
    "model_xml = os.path.join(workspace_dir, dataset, model, 'open_vino', 'frozen_inference_graph.xml')\n",
    "model_bin = os.path.join(workspace_dir, dataset, model, 'open_vino', 'frozen_inference_graph.bin')\n",
    "labels.append([l.strip() for l in open(os.path.join(workspace_dir, dataset, 'classes.txt')).readlines()])\n",
    "\n",
    "# 2. Dataset and Model\n",
    "dataset2 = 'Beispiel_Set'\n",
    "model_2 = 'ssd_inception_v2_coco_out'\n",
    "model_2_xml = os.path.join(workspace_dir, dataset2, model_2, 'open_vino', 'frozen_inference_graph.xml')\n",
    "model_2_bin = os.path.join(workspace_dir, dataset2, model_2, 'open_vino', 'frozen_inference_graph.bin')\n",
    "labels.append([l.strip() for l in open(os.path.join(workspace_dir, dataset2, 'classes.txt')).readlines()])\n",
    "\n",
    "# path to images to infer\n",
    "test_images_dir = '/home/manuel/Bachelor_Arbeit/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 images found\n"
     ]
    }
   ],
   "source": [
    "# get all image paths\n",
    "if os.path.isdir(test_images_dir):\n",
    "    images = [\n",
    "        os.path.join(test_images_dir, img) for img in os.listdir(test_images_dir) if img[-3:] == 'jpg']\n",
    "    print(str(len(images)) + ' images found')\n",
    "    #shuffle(images)\n",
    "elif os.path.isfile(test_images_dir) and test_images_dir[-3:] == 'jpg':\n",
    "    print('one image found')\n",
    "    images = [test_images_dir]\n",
    "else:\n",
    "    print('wrong input')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one plugin\n",
    "ie = IECore()\n",
    "\n",
    "# create two networks\n",
    "net = [IENetwork(model=model_xml, weights=model_bin), IENetwork(model=model_2_xml, weights=model_2_bin)]\n",
    "model_names = ['fasterrcnn animals', 'ssd sample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the two executable nets from the plugin\n",
    "exec_net = [ie.load_network(network=net[0],\n",
    "                            num_requests=2,\n",
    "                            device_name='MYRIAD'),\n",
    "            ie.load_network(network=net[1],\n",
    "                            num_requests=2,\n",
    "                            device_name='MYRIAD')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pairs needed varables 0:first_model, 1:second_model\n",
    "img_info_input_blob = [None, None]\n",
    "feed_dict = [{}, {}]\n",
    "input_blob = [None, None]\n",
    "img_info_input_blob = [None, None]\n",
    "out_blob = [None, None]\n",
    "nchw = [None, None]\n",
    "cur_request_id = [0, 0]\n",
    "next_request_id = [1, 1]\n",
    "frame = [cv2.imread(images[0]), cv2.imread(images[0])]\n",
    "initial_h = [frame[0].shape[0], frame[1].shape[0]]\n",
    "initial_w = [frame[0].shape[1], frame[1].shape[1]]\n",
    "next_frame = [None, None]\n",
    "next_initial_h = [None, None]\n",
    "next_initial_w = [None, None]\n",
    "detection_results = [None, None]\n",
    "\n",
    "# create for both networks the in- outputblobs\n",
    "for i in range(2):\n",
    "    for blob_name in net[i].inputs:\n",
    "        if len(net[i].inputs[blob_name].shape) == 4:\n",
    "            input_blob[i] = blob_name\n",
    "        elif len(net[i].inputs[blob_name].shape) == 2:\n",
    "            img_info_input_blob[i] = blob_name\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupported {}D input layer '{}'. Only 2D and 4D input layers are supported\"\n",
    "                                   .format(len(net.inputs[blob_name].shape), blob_name))\n",
    "\n",
    "    assert len(net[i].outputs) == 1, \"Demo supports only single output topologies\"\n",
    "\n",
    "    out_blob[i] = next(iter(net[i].outputs))\n",
    "    \n",
    "    nchw[i] = net[i].inputs[input_blob[i]].shape\n",
    "    \n",
    "    if img_info_input_blob[i]:\n",
    "        feed_dict[i][img_info_input_blob[i]] = [nchw[i][2], nchw[i][3], 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasterrcnn animals\n",
      "[]\n",
      "ssd sample\n",
      "[]\n",
      "fasterrcnn animals\n",
      "[]\n",
      "ssd sample\n",
      "['Human_head']\n",
      "fasterrcnn animals\n",
      "['Deer', 'Deer', 'Deer']\n",
      "ssd sample\n",
      "['Human_head']\n",
      "fasterrcnn animals\n",
      "['Deer', 'Deer', 'Deer', 'Deer', 'Deer']\n",
      "ssd sample\n",
      "[]\n",
      "fasterrcnn animals\n",
      "['Deer', 'Deer', 'Deer', 'Deer', 'Deer']\n",
      "ssd sample\n",
      "[]\n",
      "fasterrcnn animals\n",
      "[]\n",
      "ssd sample\n",
      "[]\n",
      "fasterrcnn animals\n",
      "['Deer', 'Deer', 'Deer']\n",
      "ssd sample\n",
      "['Human_head']\n",
      "fasterrcnn animals\n",
      "[]\n",
      "ssd sample\n",
      "['Mobile_phone']\n",
      "fasterrcnn animals\n",
      "['Deer', 'Deer']\n",
      "ssd sample\n",
      "['Human_head']\n",
      "fasterrcnn animals\n",
      "[]\n",
      "ssd sample\n",
      "[]\n",
      "fasterrcnn animals\n",
      "['Deer']\n",
      "ssd sample\n",
      "['Human_head']\n"
     ]
    }
   ],
   "source": [
    "# create a frame with h,w for the first run (will not be infered)\n",
    "frame = [cv2.imread(images[0]), cv2.imread(images[0])]\n",
    "initial_h = [frame[0].shape[0], frame[1].shape[0]]\n",
    "initial_w = [frame[0].shape[1], frame[1].shape[1]]\n",
    "for img_path in images:\n",
    "    \n",
    "    # set index for the first Model\n",
    "    i = 0\n",
    "    \n",
    "    # read the image from path\n",
    "    next_frame[i] = cv2.imread(img_path)\n",
    "    next_initial_h[i], next_initial_w[i] = next_frame[i].shape[: 2]\n",
    "    \n",
    "    # resize the image\n",
    "    in_frame = cv2.resize(next_frame[i], (nchw[i][3], nchw[i][2]))\n",
    "    in_frame = in_frame.transpose((2, 0, 1))\n",
    "    in_frame = in_frame.reshape((nchw[i][0], nchw[i][1], nchw[i][2], nchw[i][3]))\n",
    "    \n",
    "    # start async request for next frame\n",
    "    feed_dict[i][input_blob[i]] = in_frame\n",
    "    exec_net[i].start_async(request_id=next_request_id[i], inputs=feed_dict[i])\n",
    "    \n",
    "    # check for current frame\n",
    "    if exec_net[i].requests[cur_request_id[i]].wait(-1) == 0:\n",
    "\n",
    "        # get infer results from current frame\n",
    "        res = exec_net[i].requests[cur_request_id[i]].outputs[out_blob[i]]\n",
    "        detection_results[i] = []\n",
    "        for obj in res[0][0]:\n",
    "            if obj[2] > 0.5:\n",
    "                xmin = int(obj[3] * initial_w[i])\n",
    "                ymin = int(obj[4] * initial_h[i])\n",
    "                xmax = int(obj[5] * initial_w[i])\n",
    "                ymax = int(obj[6] * initial_h[i])\n",
    "                class_id = int(obj[1])\n",
    "                color = (min(class_id * 12.5, 255),\n",
    "                             min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "                cv2.rectangle(frame[i], (xmin, ymin),\n",
    "                                  (xmax, ymax), (255, 255, 0), 2)\n",
    "                det_label = labels[i][class_id - 1]\n",
    "                detection_results[i].append(det_label)\n",
    "                cv2.putText(frame[i], det_label + ' ' + str(round(obj[2] * 100, 1)) + ' %', (xmin, ymin - 7),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 0), 1)\n",
    "    \n",
    "    # print/show result of infered current frame \n",
    "    cv2.imshow(\"Detection Results\", frame[i])\n",
    "    print(model_names[i])\n",
    "    print(detection_results[i])\n",
    "    \n",
    "    # save a copy of the infered current frame for the next Model as Input\n",
    "    frame_tmp = np.copy(frame[i])\n",
    "    \n",
    "    # swithch request id's\n",
    "    cur_request_id[i], next_request_id[i] = next_request_id[i], cur_request_id[i]\n",
    "    \n",
    "    # current <- next\n",
    "    frame[i] = next_frame[i]\n",
    "    initial_w[i] = next_initial_w[i]\n",
    "    initial_h[i] = next_initial_h[i]\n",
    "    \n",
    "    key = cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # set index for the sectond Model\n",
    "    # Model 2 ist immer um 2 Bilder hinterher\n",
    "    i = 1\n",
    "    \n",
    "    # take the Output from Model_1 as Input\n",
    "    next_frame[i] = frame_tmp\n",
    "    next_initial_h[i], next_initial_w[i] = next_frame[i].shape[: 2]\n",
    "    \n",
    "    # resize the image\n",
    "    in_frame = cv2.resize(next_frame[i], (nchw[i][3], nchw[i][2]))\n",
    "    in_frame = in_frame.transpose((2, 0, 1))\n",
    "    in_frame = in_frame.reshape((nchw[i][0], nchw[i][1], nchw[i][2], nchw[i][3]))\n",
    "    \n",
    "    # start async request for next frame\n",
    "    feed_dict[i][input_blob[i]] = in_frame\n",
    "    exec_net[i].start_async(request_id=next_request_id[i], inputs=feed_dict[i])\n",
    "    \n",
    "    # check for current frame\n",
    "    if exec_net[i].requests[cur_request_id[i]].wait(-1) == 0:\n",
    "\n",
    "        # get infer results from current frame\n",
    "        res = exec_net[i].requests[cur_request_id[i]].outputs[out_blob[i]]\n",
    "        detection_results[i] = []\n",
    "        for obj in res[0][0]:\n",
    "            if obj[2] > 0.5:\n",
    "                xmin = int(obj[3] * initial_w[i])\n",
    "                ymin = int(obj[4] * initial_h[i])\n",
    "                xmax = int(obj[5] * initial_w[i])\n",
    "                ymax = int(obj[6] * initial_h[i])\n",
    "                class_id = int(obj[1])\n",
    "                color = (min(class_id * 12.5, 255),\n",
    "                             min(class_id * 7, 255), min(class_id * 5, 255))\n",
    "                cv2.rectangle(frame[i], (xmin, ymin),\n",
    "                                  (xmax, ymax), (255, 255, 0), 2)\n",
    "                det_label = labels[i][class_id - 1]\n",
    "                detection_results[i].append(det_label)\n",
    "                cv2.putText(frame[i], det_label + ' ' + str(round(obj[2] * 100, 1)) + ' %', (xmin, ymin - 7),\n",
    "                                cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 255, 0), 1)\n",
    "    \n",
    "    # print/show result of infered current frame \n",
    "    cv2.imshow(\"Detection Results\", frame[i])\n",
    "    print(model_names[i])\n",
    "    print(detection_results[i])\n",
    "    \n",
    "    # save a copy of the infered current frame for the next Model as Input\n",
    "    frame_tmp = np.copy(frame[i])\n",
    "    \n",
    "    # swithch request id's\n",
    "    cur_request_id[i], next_request_id[i] = next_request_id[i], cur_request_id[i]\n",
    "    \n",
    "    # current <- next\n",
    "    frame[i] = next_frame[i]\n",
    "    initial_w[i] = next_initial_w[i]\n",
    "    initial_h[i] = next_initial_h[i]\n",
    "    \n",
    "    key = cv2.waitKey(0)\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
